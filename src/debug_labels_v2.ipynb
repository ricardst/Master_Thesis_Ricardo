{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061a4b03",
   "metadata": {},
   "source": [
    "# Simple Sensor Data Visualization v2\n",
    "\n",
    "**Purpose**: Load sensor data around sync events with individual time axes for manual sync event identification.\n",
    "\n",
    "**Features**:\n",
    "- Load 4 hours around sync start time (configurable)\n",
    "- Each sensor has its own independent time axis\n",
    "- Time shifts controlled by Sync_Parameters.yaml\n",
    "- Preprocessing done before plotting\n",
    "- Simple and focused approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e3011",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c4c6fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration:\n",
      "  Subject: OutSense-425_48h\n",
      "  Time window: ¬±4 hours around sync start\n",
      "  Target frequency: 25 Hz\n",
      "  Project root: /home/muff_an/scai_data_process\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "SUBJECT_ID = \"OutSense-425_48h\"  # Change this to your subject\n",
    "HOURS_AROUND_SYNC = 4  # Hours to load around sync start time (2 hours before, 2 hours after)\n",
    "TARGET_FREQUENCY = 25  # Hz for resampling\n",
    "\n",
    "# Paths\n",
    "script_dir = os.path.dirname(os.path.abspath('.'))\n",
    "project_root = os.path.dirname(script_dir)\n",
    "sync_params_path = os.path.join(project_root, 'Sync_Parameters.yaml')\n",
    "sync_events_path = os.path.join(project_root, 'Sync_Events_Times.csv')\n",
    "config_path = os.path.join(project_root, 'config.yaml')\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  Subject: {SUBJECT_ID}\")\n",
    "print(f\"  Time window: ¬±{HOURS_AROUND_SYNC} hours around sync start\")\n",
    "print(f\"  Target frequency: {TARGET_FREQUENCY} Hz\")\n",
    "print(f\"  Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ec783",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Sync Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1a7aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded configurations:\n",
      "  Main config: 62 sections\n",
      "  Sync parameters: 16 subjects\n",
      "  Sync events: 16 entries\n",
      "\n",
      "üéØ Sync times for OutSense-425_48h:\n",
      "  Sync Start: 2023-06-27 13:59:30\n",
      "  Sync End: 2023-06-29 13:41:40\n",
      "  Duration: 1 days 23:42:10\n",
      "\n",
      "üìä Data window (4h around sync start):\n",
      "  Window Start: 2023-06-27 11:59:30\n",
      "  Window End: 2023-06-27 15:59:30\n",
      "  Total Duration: 0 days 04:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load main configuration\n",
    "with open('/home/muff_an/scai_data_process/Master_Thesis_Ricardo/config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Load sync parameters\n",
    "with open('/home/muff_an/scai_data_process/Master_Thesis_Ricardo/Sync_Parameters.yaml', 'r') as f:\n",
    "    sync_params = yaml.safe_load(f)\n",
    "\n",
    "# Load sync events\n",
    "sync_events_df = pd.read_csv('/home/muff_an/scai_data_process/Master_Thesis_Ricardo/Sync_Events_Times.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded configurations:\")\n",
    "print(f\"  Main config: {len(cfg)} sections\")\n",
    "print(f\"  Sync parameters: {len(sync_params)} subjects\")\n",
    "print(f\"  Sync events: {len(sync_events_df)} entries\")\n",
    "\n",
    "# Get sync start time for the subject\n",
    "subject_sync = sync_events_df[sync_events_df['Subject'] == SUBJECT_ID]\n",
    "if subject_sync.empty:\n",
    "    raise ValueError(f\"No sync events found for subject {SUBJECT_ID}\")\n",
    "\n",
    "sync_start_str = subject_sync.iloc[0]['Sync Start']\n",
    "sync_end_str = subject_sync.iloc[0]['Sync End']\n",
    "\n",
    "# Parse sync times\n",
    "sync_start_time = pd.to_datetime(sync_start_str, format='%d.%m.%Y.%H.%M.%S')\n",
    "sync_end_time = pd.to_datetime(sync_end_str, format='%d.%m.%Y.%H.%M.%S')\n",
    "\n",
    "print(f\"\\nüéØ Sync times for {SUBJECT_ID}:\")\n",
    "print(f\"  Sync Start: {sync_start_time}\")\n",
    "print(f\"  Sync End: {sync_end_time}\")\n",
    "print(f\"  Duration: {sync_end_time - sync_start_time}\")\n",
    "\n",
    "# Calculate data window\n",
    "data_window_start = sync_start_time - pd.Timedelta(hours=HOURS_AROUND_SYNC//2)\n",
    "data_window_end = sync_start_time + pd.Timedelta(hours=HOURS_AROUND_SYNC//2)\n",
    "\n",
    "print(f\"\\nüìä Data window ({HOURS_AROUND_SYNC}h around sync start):\")\n",
    "print(f\"  Window Start: {data_window_start}\")\n",
    "print(f\"  Window End: {data_window_end}\")\n",
    "print(f\"  Total Duration: {data_window_end - data_window_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c45dff",
   "metadata": {},
   "source": [
    "## 3. Load and Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7b8adfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imported functions from raw_data_processor\n",
      "\n",
      "üìÇ Data paths:\n",
      "  Raw data dir: /scai_data2/scai_datasets/interim/scai-outsense/\n",
      "  Subject dir: /scai_data2/scai_datasets/interim/scai-outsense/OutSense-425_48h\n",
      "  Available sensors: ['corsano_wrist_acc', 'cosinuss_ear_acc_x_acc_y_acc_z', 'mbient_imu_wc_accelerometer', 'mbient_imu_wc_gyroscope', 'vivalnk_vv330_acceleration', 'sensomative_bottom_logger', 'sensomative_back_logger', 'corsano_bioz_acc']\n"
     ]
    }
   ],
   "source": [
    "# Import data loading functions from the original notebook/scripts\n",
    "import sys\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import necessary functions (you may need to adjust these based on your actual module structure)\n",
    "try:\n",
    "    from raw_data_processor import (\n",
    "        select_data_loader,\n",
    "        modify_modality_names,\n",
    "        process_modality_duplicates,\n",
    "        handle_missing_data_interpolation,\n",
    "        correct_timestamp_drift\n",
    "    )\n",
    "    print(\"‚úÖ Imported functions from raw_data_processor\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import from raw_data_processor: {e}\")\n",
    "    print(\"You may need to adjust the import paths or copy the required functions\")\n",
    "    \n",
    "    # Define minimal data loader selection function\n",
    "    def select_data_loader(sensor_name):\n",
    "        \"\"\"Simple data loader selector - you may need to implement based on your data structure\"\"\"\n",
    "        def simple_csv_loader(subject_dir, sensor_name, sensor_settings):\n",
    "            # This is a placeholder - implement based on your actual data structure\n",
    "            csv_path = os.path.join(subject_dir, f\"{sensor_name}.csv\")\n",
    "            if os.path.exists(csv_path):\n",
    "                return pd.read_csv(csv_path)\n",
    "            else:\n",
    "                return pd.DataFrame()\n",
    "        return simple_csv_loader\n",
    "    \n",
    "    def modify_modality_names(data, sensor_name):\n",
    "        \"\"\"Simple modality name modifier\"\"\"\n",
    "        return sensor_name, data\n",
    "    \n",
    "    def process_modality_duplicates(data, sample_rate):\n",
    "        \"\"\"Simple duplicate processor\"\"\"\n",
    "        return data.drop_duplicates()\n",
    "    \n",
    "    def handle_missing_data_interpolation(data, max_interp_gap_s=2, target_freq=50):\n",
    "        \"\"\"Simple interpolation\"\"\"\n",
    "        return data.interpolate(method='linear', limit=int(max_interp_gap_s * target_freq))\n",
    "    \n",
    "    def correct_timestamp_drift(timestamp, t0, t1, drift_secs):\n",
    "        \"\"\"Simple drift correction\"\"\"\n",
    "        if t0 <= timestamp <= t1:\n",
    "            progress = (timestamp - t0) / (t1 - t0)\n",
    "            return timestamp + (drift_secs * progress)\n",
    "        return timestamp\n",
    "    \n",
    "    print(\"üìù Using simplified placeholder functions\")\n",
    "\n",
    "# Get raw data configuration\n",
    "raw_data_parsing_config = cfg.get('raw_data_parsing_config', {})\n",
    "raw_data_base_dir = os.path.join(project_root, cfg.get('raw_data_input_dir', 'data'))\n",
    "subject_dir = os.path.join(raw_data_base_dir, SUBJECT_ID)\n",
    "\n",
    "print(f\"\\nüìÇ Data paths:\")\n",
    "print(f\"  Raw data dir: {raw_data_base_dir}\")\n",
    "print(f\"  Subject dir: {subject_dir}\")\n",
    "print(f\"  Available sensors: {list(raw_data_parsing_config.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59895fa",
   "metadata": {},
   "source": [
    "## 4. Load and Process Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25ef9416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOADING SENSOR DATA ===\n",
      "Processing sensors for subject: OutSense-425_48h\n",
      "Time window: 2023-06-27 11:59:30 to 2023-06-27 15:59:30\n",
      "\n",
      "--- Processing sensor: corsano_wrist_acc ---\n",
      "üìä Loaded 5389984 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7203s\n",
      "üìê Applied drift correction: -10s over 162290.0s interval\n",
      "üîç Filtered from 5389984 to 249908 samples (4.6% retained)\n",
      "‚úÖ Final shape: (249908, 3)\n",
      "‚úÖ Time range: 2023-06-27 13:49:20.862529993 to 2023-06-27 15:59:29.974317789\n",
      "\n",
      "--- Processing sensor: cosinuss_ear_acc_x_acc_y_acc_z ---\n",
      "‚ùå No data loaded for cosinuss_ear_acc_x_acc_y_acc_z\n",
      "\n",
      "--- Processing sensor: mbient_imu_wc_accelerometer ---\n",
      "üìä Loaded 9060010 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7217s\n",
      "üìê Applied drift correction: -15s over 162290.0s interval\n",
      "üîç Filtered from 9060010 to 674417 samples (7.4% retained)\n",
      "‚úÖ Final shape: (674417, 3)\n",
      "‚úÖ Time range: 2023-06-27 12:16:52.649641514 to 2023-06-27 15:59:29.979947567\n",
      "\n",
      "--- Processing sensor: mbient_imu_wc_gyroscope ---\n",
      "üìä Loaded 9060012 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7217s\n",
      "üìê Applied drift correction: -14s over 171745.0s interval\n",
      "üîç Filtered from 9060012 to 674402 samples (7.4% retained)\n",
      "‚úÖ Final shape: (674402, 3)\n",
      "‚úÖ Time range: 2023-06-27 12:16:52.804359674 to 2023-06-27 15:59:29.986444235\n",
      "\n",
      "--- Processing sensor: vivalnk_vv330_acceleration ---\n",
      "üìä Loaded 866790 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7205s\n",
      "üìê Applied drift correction: -5s over 172800.0s interval\n",
      "üîç Filtered from 866790 to 35408 samples (4.1% retained)\n",
      "‚úÖ Final shape: (35408, 3)\n",
      "‚úÖ Time range: 2023-06-27 14:01:27.722210884 to 2023-06-27 15:59:29.917280197\n",
      "\n",
      "--- Processing sensor: sensomative_bottom_logger ---\n",
      "üìä Loaded 1810963 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7200s\n",
      "üîç Filtered from 1810963 to 39074 samples (2.2% retained)\n",
      "‚úÖ Final shape: (39070, 11)\n",
      "‚úÖ Time range: 2023-06-27 13:30:01.500000 to 2023-06-27 15:59:29.957999945\n",
      "\n",
      "--- Processing sensor: sensomative_back_logger ---\n",
      "üìä Loaded 1811158 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7200s\n",
      "üîç Filtered from 1811158 to 39086 samples (2.2% retained)\n",
      "‚úÖ Final shape: (39082, 11)\n",
      "‚úÖ Time range: 2023-06-27 13:30:01.328999996 to 2023-06-27 15:59:29.993000031\n",
      "\n",
      "--- Processing sensor: corsano_bioz_acc ---\n",
      "üìä Loaded 5377280 raw samples\n",
      "‚è±Ô∏è Applied time shift: 7202s\n",
      "üìê Applied drift correction: 2s over 162290.0s interval\n",
      "üîç Filtered from 5377280 to 249693 samples (4.6% retained)\n",
      "‚úÖ Final shape: (249693, 3)\n",
      "‚úÖ Time range: 2023-06-27 13:49:27.027567863 to 2023-06-27 15:59:29.998727560\n",
      "\n",
      "üìà Successfully processed 7 sensors:\n",
      "  üìä corsano_wrist: 249908 samples, duration 0 days 02:10:09.111787796\n",
      "  üìä mbient_acc: 674417 samples, duration 0 days 03:42:37.330306053\n",
      "  üìä mbient_gyro: 674402 samples, duration 0 days 03:42:37.182084561\n",
      "  üìä vivalnk_acc: 35408 samples, duration 0 days 01:58:02.195069313\n",
      "  üìä sensomative_bottom: 39070 samples, duration 0 days 02:29:28.457999945\n",
      "  üìä sensomative_back: 39082 samples, duration 0 days 02:29:28.664000035\n",
      "  üìä corsano_bioz: 249693 samples, duration 0 days 02:10:02.971159697\n"
     ]
    }
   ],
   "source": [
    "# Load and process each sensor with time shifts from Sync_Parameters.yaml\n",
    "print(f\"\\n=== LOADING SENSOR DATA ===\")\n",
    "print(f\"Processing sensors for subject: {SUBJECT_ID}\")\n",
    "print(f\"Time window: {data_window_start} to {data_window_end}\")\n",
    "\n",
    "processed_sensors = {}\n",
    "subject_correction_params = sync_params.get(SUBJECT_ID, {})\n",
    "\n",
    "for sensor_name, sensor_settings in raw_data_parsing_config.items():\n",
    "    print(f\"\\n--- Processing sensor: {sensor_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Load raw sensor data\n",
    "        loader = select_data_loader(sensor_name)\n",
    "        sensor_data_raw = loader(subject_dir, sensor_name, sensor_settings)\n",
    "        \n",
    "        if sensor_data_raw.empty or 'time' not in sensor_data_raw.columns:\n",
    "            print(f\"‚ùå No data loaded for {sensor_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"üìä Loaded {len(sensor_data_raw)} raw samples\")\n",
    "        \n",
    "        # Get time correction parameters for this sensor\n",
    "        sensor_corr_params = subject_correction_params.get(sensor_name, {'unit': 's'})\n",
    "        time_unit = sensor_corr_params.get('unit', 's')\n",
    "        shift_val = sensor_corr_params.get('shift', 0)\n",
    "        \n",
    "        # Apply time corrections\n",
    "        time_col_num = sensor_data_raw['time'].astype(float)\n",
    "        \n",
    "        # Convert to seconds if needed\n",
    "        if time_unit == 'ms':\n",
    "            time_col_num = time_col_num / 1000.0\n",
    "        \n",
    "        # Apply shift correction\n",
    "        if shift_val != 0:\n",
    "            time_col_num = time_col_num + shift_val\n",
    "            print(f\"‚è±Ô∏è Applied time shift: {shift_val}s\")\n",
    "        \n",
    "        # Apply drift correction if available\n",
    "        drift_params = sensor_corr_params.get('drift')\n",
    "        if drift_params and all(k in drift_params for k in ['t0', 't1', 'drift_secs']):\n",
    "            t0_ts = pd.Timestamp(drift_params['t0'])\n",
    "            t1_ts = pd.Timestamp(drift_params['t1'])\n",
    "            if not pd.isna(t0_ts) and not pd.isna(t1_ts):\n",
    "                t0, t1 = t0_ts.timestamp(), t1_ts.timestamp()\n",
    "                drift = drift_params['drift_secs']\n",
    "                time_col_num = time_col_num.apply(correct_timestamp_drift, args=(t0, t1, drift))\n",
    "                print(f\"üìê Applied drift correction: {drift}s over {t1-t0:.1f}s interval\")\n",
    "        \n",
    "        # Convert to datetime\n",
    "        corrected_timestamps = pd.to_datetime(time_col_num, unit='s', errors='coerce')\n",
    "        sensor_data_corrected = sensor_data_raw.drop(columns=['time']).copy()\n",
    "        sensor_data_corrected['time'] = corrected_timestamps\n",
    "        sensor_data_corrected.dropna(subset=['time'], inplace=True)\n",
    "        \n",
    "        if sensor_data_corrected.empty:\n",
    "            print(f\"‚ùå No valid data after time correction for {sensor_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to data window\n",
    "        original_count = len(sensor_data_corrected)\n",
    "        time_mask = (sensor_data_corrected['time'] >= data_window_start) & (sensor_data_corrected['time'] <= data_window_end)\n",
    "        sensor_data_filtered = sensor_data_corrected[time_mask].copy()\n",
    "        \n",
    "        filtered_count = len(sensor_data_filtered)\n",
    "        retention_pct = (filtered_count / original_count * 100) if original_count > 0 else 0\n",
    "        print(f\"üîç Filtered from {original_count} to {filtered_count} samples ({retention_pct:.1f}% retained)\")\n",
    "        \n",
    "        if sensor_data_filtered.empty:\n",
    "            print(f\"‚ùå No data in time window for {sensor_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Set time as index\n",
    "        sensor_data_filtered.set_index('time', inplace=True)\n",
    "        sensor_data_filtered.sort_index(inplace=True)\n",
    "        \n",
    "        # Apply basic preprocessing\n",
    "        sample_rate = sensor_settings.get('sample_rate', TARGET_FREQUENCY)\n",
    "        processed_data = process_modality_duplicates(sensor_data_filtered, sample_rate)\n",
    "        processed_data = handle_missing_data_interpolation(processed_data, max_interp_gap_s=2, target_freq=TARGET_FREQUENCY)\n",
    "        \n",
    "        # Apply column renaming\n",
    "        new_name, processed_data = modify_modality_names(processed_data, sensor_name)\n",
    "        \n",
    "        if processed_data.empty:\n",
    "            print(f\"‚ùå No data after preprocessing for {sensor_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"‚úÖ Final shape: {processed_data.shape}\")\n",
    "        print(f\"‚úÖ Time range: {processed_data.index.min()} to {processed_data.index.max()}\")\n",
    "        \n",
    "        processed_sensors[new_name] = processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing sensor {sensor_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüìà Successfully processed {len(processed_sensors)} sensors:\")\n",
    "for sensor_name, data in processed_sensors.items():\n",
    "    duration = data.index.max() - data.index.min()\n",
    "    print(f\"  üìä {sensor_name}: {len(data)} samples, duration {duration}\")\n",
    "\n",
    "if not processed_sensors:\n",
    "    raise ValueError(\"No sensor data was successfully processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d7615",
   "metadata": {},
   "source": [
    "## 5. Interactive Plotting with Independent Time Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a8d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3860c1de1042494ea74bf4794a9dafd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üéõÔ∏è Controls</h3>'), SelectMultiple(description='Select Sensors:'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interactive visualization tool is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# === Initial Sync Parameters ===\n",
    "# sync_start_time = pd.Timestamp('2022-01-01 00:05:00')\n",
    "# sync_end_time = pd.Timestamp('2022-01-01 00:06:00')\n",
    "sync_start_ref = sync_start_time  # for relative adjustments\n",
    "\n",
    "# === Widgets ===\n",
    "sensor_names = list(processed_sensors.keys())\n",
    "sensor_selection = widgets.SelectMultiple(\n",
    "    options=sensor_names,\n",
    "    value=sensor_names[:2],\n",
    "    description='Select Sensors:',\n",
    "    layout=widgets.Layout(height='150px', width='300px')\n",
    ")\n",
    "\n",
    "center_time_text = widgets.Text(\n",
    "    value=sync_start_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    description='Center Time:',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "window_minutes = widgets.IntSlider(\n",
    "    value=2,  # 1 hour window\n",
    "    min=1,\n",
    "    max=60,  # 4 hours max\n",
    "    step=1,\n",
    "    description='Window (min):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Jump buttons\n",
    "jump_sync_start = widgets.Button(description='üéØ Jump to Sync Start', button_style='success')\n",
    "jump_sync_end = widgets.Button(description='üéØ Jump to Sync End', button_style='warning')\n",
    "jump_data_start = widgets.Button(description='üìä Jump to Data Start', button_style='info')\n",
    "jump_data_end = widgets.Button(description='üìä Jump to Data End', button_style='info')\n",
    "plot_button = widgets.Button(description='üìà Plot Sensors', button_style='primary', layout=widgets.Layout(width='150px'))\n",
    "\n",
    "# Offset slider and label\n",
    "sync_offset_slider = widgets.IntSlider(\n",
    "    value=0, min=-300, max=300, step=1,\n",
    "    description='Offset (s):',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "sync_offset_label = widgets.Label(value=\"Current offset: 0 seconds\")\n",
    "\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "def get_center_time():\n",
    "    try:\n",
    "        return pd.to_datetime(center_time_text.value)\n",
    "    except:\n",
    "        return sync_start_time\n",
    "\n",
    "def update_center_time(new_time):\n",
    "    center_time_text.value = new_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def plot_sensors(_):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        selected_sensors = list(sensor_selection.value)\n",
    "        if not selected_sensors:\n",
    "            print(\"‚ùå Please select at least one sensor\")\n",
    "            return\n",
    "\n",
    "        center_time = get_center_time()\n",
    "        window_mins = window_minutes.value\n",
    "        half_window = pd.Timedelta(minutes=window_mins/2)\n",
    "        plot_start = center_time - half_window\n",
    "        plot_end = center_time + half_window\n",
    "\n",
    "        fig, axes = plt.subplots(len(selected_sensors), 1,\n",
    "                                 figsize=(16, 3*len(selected_sensors)),\n",
    "                                 sharex=False)\n",
    "        if len(selected_sensors) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, sensor_name in enumerate(selected_sensors):\n",
    "            ax = axes[i]\n",
    "            sensor_data = processed_sensors.get(sensor_name, pd.DataFrame())\n",
    "            mask = (sensor_data.index >= plot_start) & (sensor_data.index <= plot_end)\n",
    "            plot_data = sensor_data[mask]\n",
    "\n",
    "            if plot_data.empty:\n",
    "                ax.text(0.5, 0.5, f'No data in time window for {sensor_name}',\n",
    "                        ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{sensor_name} - No Data in Window')\n",
    "                continue\n",
    "\n",
    "            numeric_cols = plot_data.select_dtypes(include=[np.number]).columns\n",
    "            for col in numeric_cols:\n",
    "                ax.plot(plot_data.index, plot_data[col], label=col, alpha=0.7, linewidth=1)\n",
    "\n",
    "            # Plot lines\n",
    "            if plot_start <= sync_start_time <= plot_end:\n",
    "                ax.axvline(sync_start_time, color='red', linestyle='--', linewidth=2, alpha=0.8, label='üéØ Sync Start')\n",
    "            if plot_start <= sync_end_time <= plot_end:\n",
    "                ax.axvline(sync_end_time, color='darkred', linestyle='--', linewidth=2, alpha=0.8, label='üéØ Sync End')\n",
    "\n",
    "            ax.axvline(center_time, color='green', linestyle=':', linewidth=1, alpha=0.6, label='Center')\n",
    "\n",
    "            ax.set_title(f'{sensor_name} ({len(numeric_cols)} channels)')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "            ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=max(1, window_mins // 4)))\n",
    "            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "            if len(numeric_cols) <= 6:\n",
    "                ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "        plt.suptitle(f'Sensor Data - Independent Time Axes\\nWindow: {plot_start} to {plot_end}',\n",
    "                     fontsize=14, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.85, top=0.92)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"üéØ Sync Start: {sync_start_time}\")\n",
    "        print(f\"üéØ Sync End:   {sync_end_time}\")\n",
    "        print(f\"üïí Offset from original: {(sync_start_time - sync_start_ref).total_seconds()} seconds\")\n",
    "\n",
    "# Sync offset handler\n",
    "def on_sync_offset_slider_change(change):\n",
    "    global sync_start_time\n",
    "    offset_seconds = change['new']\n",
    "    sync_start_time = sync_start_ref + pd.Timedelta(seconds=offset_seconds)\n",
    "    sync_offset_label.value = f\"Current offset: {offset_seconds:+d} seconds\"\n",
    "    plot_sensors(None)\n",
    "\n",
    "sync_offset_slider.observe(on_sync_offset_slider_change, names='value')\n",
    "\n",
    "# Navigation button actions\n",
    "def jump_to_sync_start(_): update_center_time(sync_start_time); plot_sensors(None)\n",
    "def jump_to_sync_end(_): update_center_time(sync_end_time); plot_sensors(None)\n",
    "def jump_to_data_start(_):\n",
    "    update_center_time(min(d.index.min() for d in processed_sensors.values()))\n",
    "    plot_sensors(None)\n",
    "def jump_to_data_end(_):\n",
    "    update_center_time(max(d.index.max() for d in processed_sensors.values()))\n",
    "    plot_sensors(None)\n",
    "\n",
    "plot_button.on_click(plot_sensors)\n",
    "jump_sync_start.on_click(jump_to_sync_start)\n",
    "jump_sync_end.on_click(jump_to_sync_end)\n",
    "jump_data_start.on_click(jump_to_data_start)\n",
    "jump_data_end.on_click(jump_to_data_end)\n",
    "\n",
    "# === Display Layout ===\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üéõÔ∏è Controls</h3>\"),\n",
    "    sensor_selection,\n",
    "    center_time_text,\n",
    "    window_minutes,\n",
    "    widgets.HBox([jump_sync_start, jump_sync_end]),\n",
    "    widgets.HBox([jump_data_start, jump_data_end]),\n",
    "    plot_button\n",
    "])\n",
    "\n",
    "display(widgets.VBox([\n",
    "    controls,\n",
    "    widgets.HTML(\"<h4>üîß Adjust Sync Start Time</h4>\"),\n",
    "    sync_offset_slider,\n",
    "    sync_offset_label,\n",
    "    plot_output\n",
    "]))\n",
    "\n",
    "print(\"‚úÖ Interactive visualization tool is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c6899",
   "metadata": {},
   "source": [
    "## 6. Summary Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56472a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "Subject: OutSense-608\n",
      "Data window: 4h around sync start\n",
      "Sync start: 2024-06-04 09:39:30\n",
      "Sync end: 2024-06-06 10:57:40\n",
      "Processed sensors: 8\n",
      "\n",
      "üìä Sensor Details:\n",
      "  üìà corsano_wrist:\n",
      "    Samples: 460801\n",
      "    Time range: 2024-06-04 07:39:30 to 2024-06-04 11:39:30\n",
      "    Duration: 0 days 04:00:00\n",
      "    Columns: ['wrist_acc_x', 'wrist_acc_y', 'wrist_acc_z']\n",
      "    Time shift applied: 0s\n",
      "  üìà cosinuss_ear:\n",
      "    Samples: 205445\n",
      "    Time range: 2024-06-04 11:01:15.559000015 to 2024-06-04 11:39:29.996000051\n",
      "    Duration: 0 days 00:38:14.437000036\n",
      "    Columns: ['ear_acc_x', 'ear_acc_y', 'ear_acc_z']\n",
      "    Time shift applied: 0s\n",
      "  üìà mbient_acc:\n",
      "    Samples: 727051\n",
      "    Time range: 2024-06-04 07:39:30.003653765 to 2024-06-04 11:39:29.989685059\n",
      "    Duration: 0 days 03:59:59.986031294\n",
      "    Columns: ['x_axis_g', 'y_axis_g', 'z_axis_g']\n",
      "    Time shift applied: 0s\n",
      "  üìà mbient_gyro:\n",
      "    Samples: 727059\n",
      "    Time range: 2024-06-04 07:39:30.015814066 to 2024-06-04 11:39:29.996567965\n",
      "    Duration: 0 days 03:59:59.980753899\n",
      "    Columns: ['x_axis_dps', 'y_axis_dps', 'z_axis_dps']\n",
      "    Time shift applied: 0s\n",
      "  üìà vivalnk_acc:\n",
      "    Samples: 44910\n",
      "    Time range: 2024-06-04 08:45:05.244983912 to 2024-06-04 11:14:48.298013449\n",
      "    Duration: 0 days 02:29:43.053029537\n",
      "    Columns: ['vivalnk_acc_x', 'vivalnk_acc_y', 'vivalnk_acc_z']\n",
      "    Time shift applied: 0s\n",
      "  üìà sensomative_bottom:\n",
      "    Samples: 213109\n",
      "    Time range: 2024-06-04 07:39:30.035426855 to 2024-06-04 11:39:29.967550516\n",
      "    Duration: 0 days 03:59:59.932123661\n",
      "    Columns: ['bottom_value_1', 'bottom_value_2', 'bottom_value_3', 'bottom_value_4', 'bottom_value_5', 'bottom_value_6', 'bottom_value_7', 'bottom_value_8', 'bottom_value_9', 'bottom_value_10', 'bottom_value_11']\n",
      "    Time shift applied: 0s\n",
      "  üìà sensomative_back:\n",
      "    Samples: 212817\n",
      "    Time range: 2024-06-04 07:39:30.029999971 to 2024-06-04 11:39:29.947000027\n",
      "    Duration: 0 days 03:59:59.917000056\n",
      "    Columns: ['back_value_1', 'back_value_2', 'back_value_3', 'back_value_4', 'back_value_5', 'back_value_6', 'back_value_7', 'back_value_8', 'back_value_9', 'back_value_10', 'back_value_11']\n",
      "    Time shift applied: 0s\n",
      "  üìà corsano_bioz:\n",
      "    Samples: 435489\n",
      "    Time range: 2024-06-04 07:51:43 to 2024-06-04 11:39:30\n",
      "    Duration: 0 days 03:47:47\n",
      "    Columns: ['bioz_acc_x', 'bioz_acc_y', 'bioz_acc_z']\n",
      "    Time shift applied: 0s\n",
      "\n",
      "üéØ Ready for manual sync event identification!\n",
      "Use the interactive plot above to examine each sensor independently.\n"
     ]
    }
   ],
   "source": [
    "# Display summary information\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"Subject: {SUBJECT_ID}\")\n",
    "print(f\"Data window: {HOURS_AROUND_SYNC}h around sync start\")\n",
    "print(f\"Sync start: {sync_start_time}\")\n",
    "print(f\"Sync end: {sync_end_time}\")\n",
    "print(f\"Processed sensors: {len(processed_sensors)}\")\n",
    "\n",
    "print(\"\\nüìä Sensor Details:\")\n",
    "for sensor_name, data in processed_sensors.items():\n",
    "    # Get time shift applied\n",
    "    original_sensor_name = sensor_name  # May be modified by modify_modality_names\n",
    "    for orig_name in raw_data_parsing_config.keys():\n",
    "        if orig_name in sensor_name:\n",
    "            original_sensor_name = orig_name\n",
    "            break\n",
    "    \n",
    "    sensor_corr_params = subject_correction_params.get(original_sensor_name, {})\n",
    "    shift_applied = sensor_corr_params.get('shift', 0)\n",
    "    \n",
    "    print(f\"  üìà {sensor_name}:\")\n",
    "    print(f\"    Samples: {len(data)}\")\n",
    "    print(f\"    Time range: {data.index.min()} to {data.index.max()}\")\n",
    "    print(f\"    Duration: {data.index.max() - data.index.min()}\")\n",
    "    print(f\"    Columns: {list(data.columns)}\")\n",
    "    print(f\"    Time shift applied: {shift_applied}s\")\n",
    "\n",
    "print(\"\\nüéØ Ready for manual sync event identification!\")\n",
    "print(\"Use the interactive plot above to examine each sensor independently.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b79b6-9174-465f-8492-b18f3ab196ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
