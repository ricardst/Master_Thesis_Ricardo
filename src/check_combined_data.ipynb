{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db24198b",
   "metadata": {},
   "source": [
    "# Combined Data Checker and Interactive Visualizer\n",
    "\n",
    "**Purpose**: Load and interactively visualize the combined sensor data with labels created by debug_labels_v2.ipynb.\n",
    "\n",
    "**Features**:\n",
    "- Load combined PKL data with all sensors and labels\n",
    "- Interactive plotting with time navigation\n",
    "- Label visualization as shaded areas\n",
    "- Data quality inspection\n",
    "- Sensor selection and filtering\n",
    "- Time window controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def1dd5",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53310fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded sync events for OutSense-498:\n",
      "   Sync Start: 2024-02-15 09:13:30\n",
      "   Sync End: 2024-02-17 13:27:30\n",
      "   Duration: 2 days 04:14:00\n",
      "üìã Configuration:\n",
      "  Subject: OutSense-498\n",
      "  Base directory: /scai_data3/scratch/stirnimann_r\n",
      "  Results directory: /scai_data3/scratch/stirnimann_r/results/OutSense-498\n",
      "  Combined data file: /scai_data3/scratch/stirnimann_r/results/OutSense-498/OutSense-498_combined_data.pkl\n",
      "  Metadata file: /scai_data3/scratch/stirnimann_r/results/OutSense-498/OutSense-498_combined_data_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import random\n",
    "\n",
    "# Configuration\n",
    "SUBJECT_ID = \"OutSense-515\"  # Change this to your subject\n",
    "\n",
    "# Paths - Fixed to match actual directory structure\n",
    "base_dir = '/scai_data3/scratch/stirnimann_r'\n",
    "results_dir = os.path.join(base_dir, 'results', SUBJECT_ID)\n",
    "\n",
    "# Load sync events for navigation\n",
    "sync_events_path = os.path.join(base_dir, 'Sync_Events_Times.csv')\n",
    "sync_start_time = None\n",
    "sync_end_time = None\n",
    "\n",
    "try:\n",
    "    if os.path.exists(sync_events_path):\n",
    "        sync_events_df = pd.read_csv(sync_events_path)\n",
    "        subject_sync = sync_events_df[sync_events_df['Subject'] == SUBJECT_ID]\n",
    "        \n",
    "        if len(subject_sync) > 0:\n",
    "            sync_start_str = subject_sync.iloc[0]['Sync Start']\n",
    "            sync_end_str = subject_sync.iloc[0]['Sync End']\n",
    "            \n",
    "            sync_start_time = pd.to_datetime(sync_start_str, format='%d.%m.%Y.%H.%M.%S')\n",
    "            sync_end_time = pd.to_datetime(sync_end_str, format='%d.%m.%Y.%H.%M.%S')\n",
    "            \n",
    "            print(f\"‚úÖ Loaded sync events for {SUBJECT_ID}:\")\n",
    "            print(f\"   Sync Start: {sync_start_time}\")\n",
    "            print(f\"   Sync End: {sync_end_time}\")\n",
    "            print(f\"   Duration: {sync_end_time - sync_start_time}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No sync events found for {SUBJECT_ID}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Sync events file not found: {sync_events_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading sync events: {e}\")\n",
    "\n",
    "# File paths\n",
    "combined_data_path = os.path.join(results_dir, f'{SUBJECT_ID}_combined_data.pkl')\n",
    "metadata_path = os.path.join(results_dir, f'{SUBJECT_ID}_combined_data_metadata.json')\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  Subject: {SUBJECT_ID}\")\n",
    "print(f\"  Base directory: {base_dir}\")\n",
    "print(f\"  Results directory: {results_dir}\")\n",
    "print(f\"  Combined data file: {combined_data_path}\")\n",
    "print(f\"  Metadata file: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4dc1e",
   "metadata": {},
   "source": [
    "## 2. Load Combined Data and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093f99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING COMBINED DATA ===\n",
      "‚úÖ Loaded metadata\n",
      "üìä Loading combined data...\n",
      "‚úÖ Successfully loaded combined data!\n",
      "üìä Data shape: (3200203, 30)\n",
      "‚è±Ô∏è Time range: 2024-02-15 09:12:57 to 2024-02-16 20:46:25.157999992\n",
      "‚è±Ô∏è Duration: 1 days 11:33:28.157999992\n",
      "üìà Total columns: 30\n",
      "üìÅ File size: 747.7 MB\n",
      "\n",
      "üìã Metadata Summary:\n",
      "  Creation time: 2025-07-01T17:32:37.833310\n",
      "  Sampling frequency: 25 Hz\n",
      "  Total samples: 3200203\n",
      "  Sensors processed: 7\n",
      "  Labels available: 640\n",
      "  Labeled timestamps: 1883228\n",
      "  Label coverage: 58.8%\n"
     ]
    }
   ],
   "source": [
    "# Load the combined data\n",
    "print(\"=== LOADING COMBINED DATA ===\")\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(combined_data_path):\n",
    "    raise FileNotFoundError(f\"Combined data file not found: {combined_data_path}\")\n",
    "    \n",
    "if not os.path.exists(metadata_path):\n",
    "    print(f\"‚ö†Ô∏è Metadata file not found: {metadata_path}\")\n",
    "    metadata = {}\n",
    "else:\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"‚úÖ Loaded metadata\")\n",
    "\n",
    "# Load the combined data\n",
    "print(f\"üìä Loading combined data...\")\n",
    "with open(combined_data_path, 'rb') as f:\n",
    "    combined_data = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded combined data!\")\n",
    "print(f\"üìä Data shape: {combined_data.shape}\")\n",
    "print(f\"‚è±Ô∏è Time range: {combined_data.index.min()} to {combined_data.index.max()}\")\n",
    "print(f\"‚è±Ô∏è Duration: {combined_data.index.max() - combined_data.index.min()}\")\n",
    "print(f\"üìà Total columns: {len(combined_data.columns)}\")\n",
    "\n",
    "# Show file size\n",
    "file_size = os.path.getsize(combined_data_path)\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "print(f\"üìÅ File size: {file_size_mb:.1f} MB\")\n",
    "\n",
    "# Display metadata summary if available\n",
    "if metadata:\n",
    "    print(f\"\\nüìã Metadata Summary:\")\n",
    "    print(f\"  Creation time: {metadata.get('creation_time', 'Unknown')}\")\n",
    "    print(f\"  Sampling frequency: {metadata.get('sampling', {}).get('target_frequency_hz', 'Unknown')} Hz\")\n",
    "    print(f\"  Total samples: {metadata.get('sampling', {}).get('total_samples', 'Unknown')}\")\n",
    "    \n",
    "    sensors_info = metadata.get('sensors', {})\n",
    "    print(f\"  Sensors processed: {len(sensors_info)}\")\n",
    "    \n",
    "    labels_info = metadata.get('labels', {})\n",
    "    print(f\"  Labels available: {labels_info.get('total_labels_available', 'Unknown')}\")\n",
    "    print(f\"  Labeled timestamps: {labels_info.get('labeled_timestamps', 'Unknown')}\")\n",
    "    print(f\"  Label coverage: {labels_info.get('label_coverage_percent', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ff023",
   "metadata": {},
   "source": [
    "## 3. Data Analysis and Column Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448ed95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA STRUCTURE ANALYSIS ===\n",
      "üìä Column breakdown:\n",
      "  Sensor columns: 29\n",
      "  Label column: 1 ('Label')\n",
      "\n",
      "üìà Sensor groups identified:\n",
      "  üìä corsano_wrist_wrist_acc: 3 channels\n",
      "    Columns: ['corsano_wrist_wrist_acc_x', 'corsano_wrist_wrist_acc_y', 'corsano_wrist_wrist_acc_z']\n",
      "  üìä cosinuss_ear_ear_acc: 3 channels\n",
      "    Columns: ['cosinuss_ear_ear_acc_x', 'cosinuss_ear_ear_acc_y', 'cosinuss_ear_ear_acc_z']\n",
      "  üìä mbient_acc_x_axis: 1 channels\n",
      "    Columns: ['mbient_acc_x_axis_g']\n",
      "  üìä mbient_acc_y_axis: 1 channels\n",
      "    Columns: ['mbient_acc_y_axis_g']\n",
      "  üìä mbient_acc_z_axis: 1 channels\n",
      "    Columns: ['mbient_acc_z_axis_g']\n",
      "  üìä mbient_gyro_x_axis: 1 channels\n",
      "    Columns: ['mbient_gyro_x_axis_dps']\n",
      "  üìä mbient_gyro_y_axis: 1 channels\n",
      "    Columns: ['mbient_gyro_y_axis_dps']\n",
      "  üìä mbient_gyro_z_axis: 1 channels\n",
      "    Columns: ['mbient_gyro_z_axis_dps']\n",
      "  üìä vivalnk_acc_vivalnk_acc: 3 channels\n",
      "    Columns: ['vivalnk_acc_vivalnk_acc_x', 'vivalnk_acc_vivalnk_acc_y', 'vivalnk_acc_vivalnk_acc_z']\n",
      "  üìä sensomative_bottom_bottom_value: 11 channels\n",
      "    Columns: ['sensomative_bottom_bottom_value_1', 'sensomative_bottom_bottom_value_2', 'sensomative_bottom_bottom_value_3']...\n",
      "  üìä corsano_bioz_bioz_acc: 3 channels\n",
      "    Columns: ['corsano_bioz_bioz_acc_x', 'corsano_bioz_bioz_acc_y', 'corsano_bioz_bioz_acc_z']\n",
      "\n",
      "üè∑Ô∏è Label analysis:\n",
      "  Empty labels: 1316975 (41.2%)\n",
      "  Unique activities: 33\n",
      "  Top 10 activities:\n",
      "    üè∑Ô∏è dark: 1023149 samples (682.1 min)\n",
      "    üè∑Ô∏è conversation: 263075 samples (175.4 min)\n",
      "    üè∑Ô∏è using_computer: 179904 samples (119.9 min)\n",
      "    üè∑Ô∏è conversation_and_eatting: 120175 samples (80.1 min)\n",
      "    üè∑Ô∏è self_propulsion: 90125 samples (60.1 min)\n",
      "    üè∑Ô∏è sitting_wheelchair: 28775 samples (19.2 min)\n",
      "    üè∑Ô∏è toilet_routine: 23675 samples (15.8 min)\n",
      "    üè∑Ô∏è using_phone: 20925 samples (13.9 min)\n",
      "    üè∑Ô∏è preparing_meal: 19550 samples (13.0 min)\n",
      "    üè∑Ô∏è lying: 19550 samples (13.0 min)\n",
      "\n",
      "üé® Generated colors for 33 unique labels\n",
      "\n",
      "üîç Data quality check:\n",
      "  ‚ö†Ô∏è Missing data detected:\n",
      "    corsano_wrist_wrist_acc_x: 262255 samples (8.2%)\n",
      "    corsano_wrist_wrist_acc_y: 262255 samples (8.2%)\n",
      "    corsano_wrist_wrist_acc_z: 262255 samples (8.2%)\n",
      "    cosinuss_ear_ear_acc_x: 2230076 samples (69.7%)\n",
      "    cosinuss_ear_ear_acc_y: 2230076 samples (69.7%)\n",
      "    cosinuss_ear_ear_acc_z: 2230076 samples (69.7%)\n",
      "    vivalnk_acc_vivalnk_acc_x: 2071351 samples (64.7%)\n",
      "    vivalnk_acc_vivalnk_acc_y: 2071351 samples (64.7%)\n",
      "    vivalnk_acc_vivalnk_acc_z: 2071351 samples (64.7%)\n",
      "    corsano_bioz_bioz_acc_x: 243525 samples (7.6%)\n",
      "    corsano_bioz_bioz_acc_y: 243525 samples (7.6%)\n",
      "    corsano_bioz_bioz_acc_z: 243525 samples (7.6%)\n",
      "\n",
      "üëÄ Data sample (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "corsano_wrist_wrist_acc_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corsano_wrist_wrist_acc_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corsano_wrist_wrist_acc_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cosinuss_ear_ear_acc_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cosinuss_ear_ear_acc_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cosinuss_ear_ear_acc_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_acc_x_axis_g",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_acc_y_axis_g",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_acc_z_axis_g",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_gyro_x_axis_dps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_gyro_y_axis_dps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mbient_gyro_z_axis_dps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vivalnk_acc_vivalnk_acc_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vivalnk_acc_vivalnk_acc_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vivalnk_acc_vivalnk_acc_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sensomative_bottom_bottom_value_11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corsano_bioz_bioz_acc_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corsano_bioz_bioz_acc_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corsano_bioz_bioz_acc_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5480c7f0-58a5-4019-a00e-311dd2b34388",
       "rows": [
        [
         "2024-02-15 09:12:57",
         "-22.0",
         "516.0",
         "-24.0",
         null,
         null,
         null,
         "-0.14200000000000002",
         "0.0215",
         "1.0074999999999998",
         "-0.061",
         "-0.3355",
         "0.0",
         "1236.0",
         "1665.0",
         "174.0",
         "99.0",
         "9.0",
         "166.0",
         "104.0",
         "108.0",
         "30.0",
         "81.0",
         "69.0",
         "100.0",
         "95.0",
         "1.0",
         "1.5",
         "498.0",
         "-7.5",
         ""
        ],
        [
         "2024-02-15 09:12:57.040000024",
         "-19.0",
         "509.0",
         "-24.0",
         null,
         null,
         null,
         "-0.1485",
         "0.019999999999999997",
         "1.0065",
         "-0.061",
         "-0.2135",
         "-0.305",
         "1236.0",
         "1665.0",
         "174.0",
         "98.5",
         "9.5",
         "169.0",
         "104.0",
         "108.0",
         "30.5",
         "81.0",
         "69.5",
         "100.0",
         "95.0",
         "1.0",
         "1.0",
         "498.0",
         "-8.0",
         ""
        ],
        [
         "2024-02-15 09:12:57.080000048",
         "-20.0",
         "507.0",
         "-25.0",
         null,
         null,
         null,
         "-0.1405",
         "0.020499999999999997",
         "1.009",
         "0.0915",
         "-0.305",
         "-0.122",
         "1213.6",
         "1667.2",
         "213.6",
         "98.0",
         "10.0",
         "172.0",
         "104.0",
         "108.0",
         "31.0",
         "81.0",
         "70.0",
         "100.0",
         "95.0",
         "1.0",
         "1.0",
         "497.0",
         "-7.0",
         ""
        ],
        [
         "2024-02-15 09:12:57.120000073",
         "-22.5",
         "511.0",
         "-24.5",
         null,
         null,
         null,
         "-0.138",
         "0.021",
         "1.0065",
         "0.0",
         "-0.39649999999999996",
         "-0.1525",
         "1191.2",
         "1669.4",
         "253.2",
         "98.0",
         "10.0",
         "176.0",
         "105.0",
         "108.0",
         "31.0",
         "80.0",
         "72.0",
         "103.0",
         "95.0",
         "1.0",
         "0.0",
         "497.0",
         "-6.5",
         ""
        ],
        [
         "2024-02-15 09:12:57.160000097",
         "-23.0",
         "511.0",
         "-25.0",
         null,
         null,
         null,
         "-0.1465",
         "0.02",
         "1.0065",
         "-0.0915",
         "-0.366",
         "-0.27449999999999997",
         "1168.8",
         "1671.6",
         "292.8",
         "96.0",
         "10.0",
         "180.0",
         "105.0",
         "109.0",
         "31.0",
         "80.0",
         "72.0",
         "103.0",
         "94.0",
         "1.0",
         "0.0",
         "499.0",
         "-7.0",
         ""
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corsano_wrist_wrist_acc_x</th>\n",
       "      <th>corsano_wrist_wrist_acc_y</th>\n",
       "      <th>corsano_wrist_wrist_acc_z</th>\n",
       "      <th>cosinuss_ear_ear_acc_x</th>\n",
       "      <th>cosinuss_ear_ear_acc_y</th>\n",
       "      <th>cosinuss_ear_ear_acc_z</th>\n",
       "      <th>mbient_acc_x_axis_g</th>\n",
       "      <th>mbient_acc_y_axis_g</th>\n",
       "      <th>mbient_acc_z_axis_g</th>\n",
       "      <th>mbient_gyro_x_axis_dps</th>\n",
       "      <th>...</th>\n",
       "      <th>sensomative_bottom_bottom_value_6</th>\n",
       "      <th>sensomative_bottom_bottom_value_7</th>\n",
       "      <th>sensomative_bottom_bottom_value_8</th>\n",
       "      <th>sensomative_bottom_bottom_value_9</th>\n",
       "      <th>sensomative_bottom_bottom_value_10</th>\n",
       "      <th>sensomative_bottom_bottom_value_11</th>\n",
       "      <th>corsano_bioz_bioz_acc_x</th>\n",
       "      <th>corsano_bioz_bioz_acc_y</th>\n",
       "      <th>corsano_bioz_bioz_acc_z</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-15 09:12:57.000000000</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1420</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>-0.0610</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>498.0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 09:12:57.040000024</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1485</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>-0.0610</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 09:12:57.080000048</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1405</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 09:12:57.120000073</th>\n",
       "      <td>-22.5</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1380</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 09:12:57.160000097</th>\n",
       "      <td>-23.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1465</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               corsano_wrist_wrist_acc_x  \\\n",
       "2024-02-15 09:12:57.000000000                      -22.0   \n",
       "2024-02-15 09:12:57.040000024                      -19.0   \n",
       "2024-02-15 09:12:57.080000048                      -20.0   \n",
       "2024-02-15 09:12:57.120000073                      -22.5   \n",
       "2024-02-15 09:12:57.160000097                      -23.0   \n",
       "\n",
       "                               corsano_wrist_wrist_acc_y  \\\n",
       "2024-02-15 09:12:57.000000000                      516.0   \n",
       "2024-02-15 09:12:57.040000024                      509.0   \n",
       "2024-02-15 09:12:57.080000048                      507.0   \n",
       "2024-02-15 09:12:57.120000073                      511.0   \n",
       "2024-02-15 09:12:57.160000097                      511.0   \n",
       "\n",
       "                               corsano_wrist_wrist_acc_z  \\\n",
       "2024-02-15 09:12:57.000000000                      -24.0   \n",
       "2024-02-15 09:12:57.040000024                      -24.0   \n",
       "2024-02-15 09:12:57.080000048                      -25.0   \n",
       "2024-02-15 09:12:57.120000073                      -24.5   \n",
       "2024-02-15 09:12:57.160000097                      -25.0   \n",
       "\n",
       "                               cosinuss_ear_ear_acc_x  cosinuss_ear_ear_acc_y  \\\n",
       "2024-02-15 09:12:57.000000000                     NaN                     NaN   \n",
       "2024-02-15 09:12:57.040000024                     NaN                     NaN   \n",
       "2024-02-15 09:12:57.080000048                     NaN                     NaN   \n",
       "2024-02-15 09:12:57.120000073                     NaN                     NaN   \n",
       "2024-02-15 09:12:57.160000097                     NaN                     NaN   \n",
       "\n",
       "                               cosinuss_ear_ear_acc_z  mbient_acc_x_axis_g  \\\n",
       "2024-02-15 09:12:57.000000000                     NaN              -0.1420   \n",
       "2024-02-15 09:12:57.040000024                     NaN              -0.1485   \n",
       "2024-02-15 09:12:57.080000048                     NaN              -0.1405   \n",
       "2024-02-15 09:12:57.120000073                     NaN              -0.1380   \n",
       "2024-02-15 09:12:57.160000097                     NaN              -0.1465   \n",
       "\n",
       "                               mbient_acc_y_axis_g  mbient_acc_z_axis_g  \\\n",
       "2024-02-15 09:12:57.000000000               0.0215               1.0075   \n",
       "2024-02-15 09:12:57.040000024               0.0200               1.0065   \n",
       "2024-02-15 09:12:57.080000048               0.0205               1.0090   \n",
       "2024-02-15 09:12:57.120000073               0.0210               1.0065   \n",
       "2024-02-15 09:12:57.160000097               0.0200               1.0065   \n",
       "\n",
       "                               mbient_gyro_x_axis_dps  ...  \\\n",
       "2024-02-15 09:12:57.000000000                 -0.0610  ...   \n",
       "2024-02-15 09:12:57.040000024                 -0.0610  ...   \n",
       "2024-02-15 09:12:57.080000048                  0.0915  ...   \n",
       "2024-02-15 09:12:57.120000073                  0.0000  ...   \n",
       "2024-02-15 09:12:57.160000097                 -0.0915  ...   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_6  \\\n",
       "2024-02-15 09:12:57.000000000                               30.0   \n",
       "2024-02-15 09:12:57.040000024                               30.5   \n",
       "2024-02-15 09:12:57.080000048                               31.0   \n",
       "2024-02-15 09:12:57.120000073                               31.0   \n",
       "2024-02-15 09:12:57.160000097                               31.0   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_7  \\\n",
       "2024-02-15 09:12:57.000000000                               81.0   \n",
       "2024-02-15 09:12:57.040000024                               81.0   \n",
       "2024-02-15 09:12:57.080000048                               81.0   \n",
       "2024-02-15 09:12:57.120000073                               80.0   \n",
       "2024-02-15 09:12:57.160000097                               80.0   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_8  \\\n",
       "2024-02-15 09:12:57.000000000                               69.0   \n",
       "2024-02-15 09:12:57.040000024                               69.5   \n",
       "2024-02-15 09:12:57.080000048                               70.0   \n",
       "2024-02-15 09:12:57.120000073                               72.0   \n",
       "2024-02-15 09:12:57.160000097                               72.0   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_9  \\\n",
       "2024-02-15 09:12:57.000000000                              100.0   \n",
       "2024-02-15 09:12:57.040000024                              100.0   \n",
       "2024-02-15 09:12:57.080000048                              100.0   \n",
       "2024-02-15 09:12:57.120000073                              103.0   \n",
       "2024-02-15 09:12:57.160000097                              103.0   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_10  \\\n",
       "2024-02-15 09:12:57.000000000                                95.0   \n",
       "2024-02-15 09:12:57.040000024                                95.0   \n",
       "2024-02-15 09:12:57.080000048                                95.0   \n",
       "2024-02-15 09:12:57.120000073                                95.0   \n",
       "2024-02-15 09:12:57.160000097                                94.0   \n",
       "\n",
       "                               sensomative_bottom_bottom_value_11  \\\n",
       "2024-02-15 09:12:57.000000000                                 1.0   \n",
       "2024-02-15 09:12:57.040000024                                 1.0   \n",
       "2024-02-15 09:12:57.080000048                                 1.0   \n",
       "2024-02-15 09:12:57.120000073                                 1.0   \n",
       "2024-02-15 09:12:57.160000097                                 1.0   \n",
       "\n",
       "                               corsano_bioz_bioz_acc_x  \\\n",
       "2024-02-15 09:12:57.000000000                      1.5   \n",
       "2024-02-15 09:12:57.040000024                      1.0   \n",
       "2024-02-15 09:12:57.080000048                      1.0   \n",
       "2024-02-15 09:12:57.120000073                      0.0   \n",
       "2024-02-15 09:12:57.160000097                      0.0   \n",
       "\n",
       "                               corsano_bioz_bioz_acc_y  \\\n",
       "2024-02-15 09:12:57.000000000                    498.0   \n",
       "2024-02-15 09:12:57.040000024                    498.0   \n",
       "2024-02-15 09:12:57.080000048                    497.0   \n",
       "2024-02-15 09:12:57.120000073                    497.0   \n",
       "2024-02-15 09:12:57.160000097                    499.0   \n",
       "\n",
       "                               corsano_bioz_bioz_acc_z  Label  \n",
       "2024-02-15 09:12:57.000000000                     -7.5         \n",
       "2024-02-15 09:12:57.040000024                     -8.0         \n",
       "2024-02-15 09:12:57.080000048                     -7.0         \n",
       "2024-02-15 09:12:57.120000073                     -6.5         \n",
       "2024-02-15 09:12:57.160000097                     -7.0         \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã All columns (30):\n",
      "   1. corsano_wrist_wrist_acc_x\n",
      "   2. corsano_wrist_wrist_acc_y\n",
      "   3. corsano_wrist_wrist_acc_z\n",
      "   4. cosinuss_ear_ear_acc_x\n",
      "   5. cosinuss_ear_ear_acc_y\n",
      "   6. cosinuss_ear_ear_acc_z\n",
      "   7. mbient_acc_x_axis_g\n",
      "   8. mbient_acc_y_axis_g\n",
      "   9. mbient_acc_z_axis_g\n",
      "  10. mbient_gyro_x_axis_dps\n",
      "  11. mbient_gyro_y_axis_dps\n",
      "  12. mbient_gyro_z_axis_dps\n",
      "  13. vivalnk_acc_vivalnk_acc_x\n",
      "  14. vivalnk_acc_vivalnk_acc_y\n",
      "  15. vivalnk_acc_vivalnk_acc_z\n",
      "  16. sensomative_bottom_bottom_value_1\n",
      "  17. sensomative_bottom_bottom_value_2\n",
      "  18. sensomative_bottom_bottom_value_3\n",
      "  19. sensomative_bottom_bottom_value_4\n",
      "  20. sensomative_bottom_bottom_value_5\n",
      "      ... and 10 more columns\n"
     ]
    }
   ],
   "source": [
    "# Analyze the data structure\n",
    "print(\"=== DATA STRUCTURE ANALYSIS ===\")\n",
    "\n",
    "# Separate sensor columns from label column\n",
    "label_column = 'Label'\n",
    "sensor_columns = [col for col in combined_data.columns if col != label_column]\n",
    "\n",
    "print(f\"üìä Column breakdown:\")\n",
    "print(f\"  Sensor columns: {len(sensor_columns)}\")\n",
    "print(f\"  Label column: 1 ('{label_column}')\")\n",
    "\n",
    "# Group columns by sensor type\n",
    "sensor_groups = {}\n",
    "for col in sensor_columns:\n",
    "    # Extract sensor prefix (everything before the last underscore)\n",
    "    parts = col.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        sensor_name = '_'.join(parts[:-1])  # All parts except the last one\n",
    "    else:\n",
    "        sensor_name = col\n",
    "    \n",
    "    if sensor_name not in sensor_groups:\n",
    "        sensor_groups[sensor_name] = []\n",
    "    sensor_groups[sensor_name].append(col)\n",
    "\n",
    "print(f\"\\nüìà Sensor groups identified:\")\n",
    "for sensor_name, columns in sensor_groups.items():\n",
    "    print(f\"  üìä {sensor_name}: {len(columns)} channels\")\n",
    "    print(f\"    Columns: {columns[:3]}{'...' if len(columns) > 3 else ''}\")\n",
    "\n",
    "# Analyze labels\n",
    "if label_column in combined_data.columns:\n",
    "    label_stats = combined_data[label_column].value_counts()\n",
    "    non_empty_labels = label_stats[label_stats.index != '']\n",
    "    empty_count = label_stats.get('', 0)\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Label analysis:\")\n",
    "    print(f\"  Empty labels: {empty_count} ({empty_count/len(combined_data)*100:.1f}%)\")\n",
    "    print(f\"  Unique activities: {len(non_empty_labels)}\")\n",
    "    \n",
    "    if len(non_empty_labels) > 0:\n",
    "        print(f\"  Top 10 activities:\")\n",
    "        for label, count in non_empty_labels.head(10).items():\n",
    "            duration_min = count / (metadata.get('sampling', {}).get('target_frequency_hz', 25)) / 60\n",
    "            print(f\"    üè∑Ô∏è {label}: {count} samples ({duration_min:.1f} min)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è No label column found in data\")\n",
    "    non_empty_labels = pd.Series()\n",
    "\n",
    "# Generate colors for labels\n",
    "def generate_label_colors(labels_list):\n",
    "    \"\"\"Generate consistent random colors for each unique label\"\"\"\n",
    "    unique_labels = list(set(labels_list))\n",
    "    random.seed(42)  # For consistent colors across runs\n",
    "    colors = []\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        # Use HSV color space for better color distribution\n",
    "        hue = (i * 137.5) % 360  # Golden angle for good distribution\n",
    "        saturation = 0.7 + (i % 3) * 0.1  # Vary saturation\n",
    "        value = 0.8 + (i % 2) * 0.15  # Vary brightness\n",
    "        \n",
    "        # Convert HSV to RGB\n",
    "        rgb = mcolors.hsv_to_rgb([hue/360, saturation, value])\n",
    "        colors.append(rgb)\n",
    "    \n",
    "    return dict(zip(unique_labels, colors))\n",
    "\n",
    "# Generate colors for labels\n",
    "if len(non_empty_labels) > 0:\n",
    "    label_colors = generate_label_colors(non_empty_labels.index.tolist())\n",
    "    print(f\"\\nüé® Generated colors for {len(label_colors)} unique labels\")\n",
    "else:\n",
    "    label_colors = {}\n",
    "    print(f\"\\nüé® No labels to color\")\n",
    "\n",
    "# Data quality check\n",
    "print(f\"\\nüîç Data quality check:\")\n",
    "missing_data = combined_data[sensor_columns].isnull().sum()\n",
    "total_missing = missing_data.sum()\n",
    "\n",
    "if total_missing > 0:\n",
    "    print(f\"  ‚ö†Ô∏è Missing data detected:\")\n",
    "    for col, missing_count in missing_data[missing_data > 0].items():\n",
    "        missing_pct = missing_count / len(combined_data) * 100\n",
    "        print(f\"    {col}: {missing_count} samples ({missing_pct:.1f}%)\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ No missing data in sensor columns\")\n",
    "\n",
    "# Show sample of data\n",
    "print(f\"\\nüëÄ Data sample (first 5 rows):\")\n",
    "display(combined_data.head())\n",
    "\n",
    "# Show columns list for reference\n",
    "print(f\"\\nüìã All columns ({len(combined_data.columns)}):\")\n",
    "for i, col in enumerate(combined_data.columns):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "    if i >= 19:  # Show first 20 columns\n",
    "        remaining = len(combined_data.columns) - 20\n",
    "        if remaining > 0:\n",
    "            print(f\"      ... and {remaining} more columns\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23ed8b",
   "metadata": {},
   "source": [
    "## 4. Interactive Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTERACTIVE DATA VISUALIZATION ===\n",
      "üéØ Interactive plotting with sensor selection and label overlay\n",
      "üîç Navigate through the combined synchronized data\n",
      "‚úÖ Interactive controls ready!\n"
     ]
    }
   ],
   "source": [
    "# Create interactive plotting tool\n",
    "print(\"=== INTERACTIVE DATA VISUALIZATION ===\")\n",
    "print(\"üéØ Interactive plotting with sensor selection and label overlay\")\n",
    "print(\"üîç Navigate through the combined synchronized data\")\n",
    "\n",
    "# Create controls\n",
    "# Sensor group selection\n",
    "sensor_group_selection = widgets.SelectMultiple(\n",
    "    options=list(sensor_groups.keys()),\n",
    "    value=list(sensor_groups.keys())[:2] if len(sensor_groups) >= 2 else list(sensor_groups.keys()),\n",
    "    description='Select Sensors:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(height='150px', width='300px')\n",
    ")\n",
    "\n",
    "# Individual channel selection (will be updated based on sensor group selection)\n",
    "channel_selection = widgets.SelectMultiple(\n",
    "    options=sensor_columns[:20],  # Start with first 20 channels\n",
    "    value=sensor_columns[:5] if len(sensor_columns) >= 5 else sensor_columns,\n",
    "    description='Select Channels:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(height='200px', width='350px')\n",
    ")\n",
    "\n",
    "# Label display controls\n",
    "show_labels = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Labels',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "label_alpha = widgets.FloatSlider(\n",
    "    value=0.3,\n",
    "    min=0.1,\n",
    "    max=0.8,\n",
    "    step=0.1,\n",
    "    description='Label Alpha:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Label filter\n",
    "if len(non_empty_labels) > 0:\n",
    "    label_filter = widgets.SelectMultiple(\n",
    "        options=list(non_empty_labels.index),\n",
    "        value=list(non_empty_labels.index)[:10] if len(non_empty_labels) > 10 else list(non_empty_labels.index),\n",
    "        description='Show Labels:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(height='150px', width='300px')\n",
    "    )\n",
    "else:\n",
    "    label_filter = widgets.SelectMultiple(\n",
    "        options=[],\n",
    "        value=[],\n",
    "        description='Show Labels:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(height='150px', width='300px')\n",
    "    )\n",
    "\n",
    "# Time window controls\n",
    "data_start = combined_data.index.min()\n",
    "data_end = combined_data.index.max()\n",
    "data_center = data_start + (data_end - data_start) / 2\n",
    "\n",
    "center_time_text = widgets.Text(\n",
    "    value=data_center.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    description='Center Time:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "window_minutes = widgets.IntSlider(\n",
    "    value=10,  # 10 minute window\n",
    "    min=1,\n",
    "    max=120,  # 2 hours max\n",
    "    step=1,\n",
    "    description='Window (min):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Navigation buttons\n",
    "nav_backward_5min = widgets.Button(description='‚è™ -5min', button_style='', \n",
    "                                  layout=widgets.Layout(width='90px'))\n",
    "nav_forward_5min = widgets.Button(description='‚è© +5min', button_style='', \n",
    "                                 layout=widgets.Layout(width='90px'))\n",
    "\n",
    "nav_backward_30min = widgets.Button(description='‚è™ -30min', button_style='', \n",
    "                                   layout=widgets.Layout(width='100px'))\n",
    "nav_forward_30min = widgets.Button(description='‚è© +30min', button_style='', \n",
    "                                  layout=widgets.Layout(width='100px'))\n",
    "\n",
    "# Quick jump buttons\n",
    "jump_data_start = widgets.Button(description='üîù Data Start', button_style='info')\n",
    "jump_data_center = widgets.Button(description='üéØ Data Center', button_style='success')\n",
    "jump_data_end = widgets.Button(description='üîö Data End', button_style='info')\n",
    "\n",
    "# Sync jump buttons (if sync times are available)\n",
    "sync_jump_buttons = []\n",
    "if sync_start_time is not None:\n",
    "    jump_sync_start = widgets.Button(description='üéØ Sync Start', button_style='warning',\n",
    "                                   layout=widgets.Layout(width='110px'))\n",
    "    sync_jump_buttons.append(jump_sync_start)\n",
    "\n",
    "if sync_end_time is not None:\n",
    "    jump_sync_end = widgets.Button(description='üéØ Sync End', button_style='warning',\n",
    "                                 layout=widgets.Layout(width='110px'))\n",
    "    sync_jump_buttons.append(jump_sync_end)\n",
    "\n",
    "# Plot controls\n",
    "plot_style = widgets.Dropdown(\n",
    "    options=['overlay', 'subplots'],\n",
    "    value='overlay',\n",
    "    description='Plot Style:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "auto_plot = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Auto-plot on navigation',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "plot_button = widgets.Button(description='üìà Plot Data', button_style='primary', \n",
    "                            layout=widgets.Layout(width='150px'))\n",
    "\n",
    "# Output area\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "# Function to update channel selection based on sensor groups\n",
    "def update_channel_selection(*args):\n",
    "    selected_sensors = list(sensor_group_selection.value)\n",
    "    available_channels = []\n",
    "    \n",
    "    for sensor in selected_sensors:\n",
    "        if sensor in sensor_groups:\n",
    "            available_channels.extend(sensor_groups[sensor])\n",
    "    \n",
    "    # Update channel selection options\n",
    "    channel_selection.options = available_channels\n",
    "    # Select first few channels by default\n",
    "    default_selection = available_channels[:min(10, len(available_channels))]\n",
    "    channel_selection.value = default_selection\n",
    "\n",
    "# Connect sensor group selection to channel selection update\n",
    "sensor_group_selection.observe(update_channel_selection, names='value')\n",
    "\n",
    "# Helper functions\n",
    "def get_center_time():\n",
    "    \"\"\"Get center time from text widget\"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(center_time_text.value)\n",
    "    except:\n",
    "        return data_center\n",
    "\n",
    "def update_center_time(new_time):\n",
    "    \"\"\"Update center time text widget\"\"\"\n",
    "    # Ensure time is within data bounds\n",
    "    new_time = max(data_start, min(data_end, new_time))\n",
    "    center_time_text.value = new_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def plot_data(btn):\n",
    "    \"\"\"Plot selected channels with labels\"\"\"\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        try:\n",
    "            from matplotlib.patches import Patch  # For creating legend handles\n",
    "            selected_channels = list(channel_selection.value)\n",
    "            if not selected_channels:\n",
    "                print(\"‚ùå Please select at least one channel\")\n",
    "                return\n",
    "            \n",
    "            center_time = get_center_time()\n",
    "            window_mins = window_minutes.value\n",
    "            \n",
    "            # Calculate time window\n",
    "            half_window = pd.Timedelta(minutes=window_mins/2)\n",
    "            plot_start = center_time - half_window\n",
    "            plot_end = center_time + half_window\n",
    "            \n",
    "            # Ensure we don't go beyond data bounds\n",
    "            plot_start = max(plot_start, data_start)\n",
    "            plot_end = min(plot_end, data_end)\n",
    "            \n",
    "            print(f\"üìä Plotting {len(selected_channels)} channels\")\n",
    "            print(f\"‚è±Ô∏è Time window: {plot_start} to {plot_end} ({window_mins} minutes)\")\n",
    "            print(f\"üéØ Center time: {center_time}\")\n",
    "            \n",
    "            # Filter data for plot window\n",
    "            mask = (combined_data.index >= plot_start) & (combined_data.index <= plot_end)\n",
    "            plot_data = combined_data[mask].copy()\n",
    "            \n",
    "            if plot_data.empty:\n",
    "                print(\"‚ùå No data in selected time window\")\n",
    "                print(f\"   Requested window: {plot_start} to {plot_end}\")\n",
    "                print(f\"   Data available: {data_start} to {data_end}\")\n",
    "                \n",
    "                # Find nearest data\n",
    "                if plot_start > data_end:\n",
    "                    time_diff = plot_start - data_end\n",
    "                    print(f\"   Window starts {time_diff} after data ends\")\n",
    "                elif plot_end < data_start:\n",
    "                    time_diff = data_start - plot_end\n",
    "                    print(f\"   Window ends {time_diff} before data starts\")\n",
    "                else:\n",
    "                    print(f\"   Window overlaps with data range but no samples found\")\n",
    "                    # Check for sparse data\n",
    "                    extended_mask = (combined_data.index >= plot_start - pd.Timedelta(hours=1)) & (combined_data.index <= plot_end + pd.Timedelta(hours=1))\n",
    "                    nearby_data = combined_data[extended_mask]\n",
    "                    if not nearby_data.empty:\n",
    "                        print(f\"   Found {len(nearby_data)} samples within ¬±1 hour\")\n",
    "                        print(f\"   Closest before: {nearby_data[nearby_data.index <= plot_start].index.max() if len(nearby_data[nearby_data.index <= plot_start]) > 0 else 'None'}\")\n",
    "                        print(f\"   Closest after: {nearby_data[nearby_data.index >= plot_end].index.min() if len(nearby_data[nearby_data.index >= plot_end]) > 0 else 'None'}\")\n",
    "                \n",
    "                return\n",
    "            \n",
    "            print(f\"üìä Plotting {len(plot_data)} samples\")\n",
    "            \n",
    "            # Create plot based on style\n",
    "            if plot_style.value == 'overlay':\n",
    "                # Single plot with all channels overlaid\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "                \n",
    "                # Plot each selected channel\n",
    "                for i, channel in enumerate(selected_channels):\n",
    "                    if channel in plot_data.columns:\n",
    "                        # Normalize data to [0,1] range for better overlay visualization\n",
    "                        data_col = plot_data[channel].dropna()\n",
    "                        if len(data_col) > 0:\n",
    "                            # Normalize to 0-1 range, then shift by channel index\n",
    "                            data_min, data_max = data_col.min(), data_col.max()\n",
    "                            if data_max > data_min:\n",
    "                                normalized_data = (data_col - data_min) / (data_max - data_min) + i\n",
    "                            else:\n",
    "                                normalized_data = data_col + i\n",
    "                            \n",
    "                            ax.plot(data_col.index, normalized_data, \n",
    "                                   label=channel, alpha=0.8, linewidth=1)\n",
    "                \n",
    "                axes = [ax]\n",
    "                \n",
    "            else:\n",
    "                # Subplots for each channel\n",
    "                fig, axes = plt.subplots(len(selected_channels), 1, \n",
    "                                       figsize=(16, 3*len(selected_channels)), \n",
    "                                       sharex=True)\n",
    "                if len(selected_channels) == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for i, (ax, channel) in enumerate(zip(axes, selected_channels)):\n",
    "                    if channel in plot_data.columns:\n",
    "                        data_col = plot_data[channel].dropna()\n",
    "                        if len(data_col) > 0:\n",
    "                            ax.plot(data_col.index, data_col, \n",
    "                                   color=f'C{i}', alpha=0.8, linewidth=1)\n",
    "                            ax.set_ylabel(channel.split('_')[-1])  # Use last part as ylabel\n",
    "                            ax.set_title(channel)\n",
    "                            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add labels to all subplots\n",
    "            visible_activity_labels = []\n",
    "            if show_labels.value and len(non_empty_labels) > 0:\n",
    "                selected_label_types = list(label_filter.value)\n",
    "                \n",
    "                # Find labels in the plot window\n",
    "                plot_labels_data = plot_data[plot_data[label_column].isin(selected_label_types)]\n",
    "                \n",
    "                if len(plot_labels_data) > 0:\n",
    "                    # Track visible labels for legend\n",
    "                    visible_activity_labels = list(set(plot_labels_data[label_column].values))\n",
    "                    visible_activity_labels = [label for label in visible_activity_labels if label in selected_label_types]\n",
    "                    \n",
    "                    # Group consecutive timestamps with same label\n",
    "                    label_segments = []\n",
    "                    current_label = None\n",
    "                    segment_start = None\n",
    "                    \n",
    "                    for timestamp, row in plot_labels_data.iterrows():\n",
    "                        label = row[label_column]\n",
    "                        if label != current_label:\n",
    "                            if current_label is not None:\n",
    "                                label_segments.append((current_label, segment_start, timestamp))\n",
    "                            current_label = label\n",
    "                            segment_start = timestamp\n",
    "                    \n",
    "                    # Add final segment\n",
    "                    if current_label is not None:\n",
    "                        label_segments.append((current_label, segment_start, plot_labels_data.index[-1]))\n",
    "                    \n",
    "                    # Add shaded regions to all axes\n",
    "                    for ax in axes:\n",
    "                        y_min, y_max = ax.get_ylim()\n",
    "                        \n",
    "                        for label_name, start_time, end_time in label_segments:\n",
    "                            if label_name in selected_label_types:\n",
    "                                color = label_colors.get(label_name, 'gray')\n",
    "                                ax.axvspan(start_time, end_time, \n",
    "                                         alpha=label_alpha.value, \n",
    "                                         color=color,\n",
    "                                         zorder=0)\n",
    "                                \n",
    "                                # Add label text for longer segments\n",
    "                                duration = end_time - start_time\n",
    "                                if duration > pd.Timedelta(minutes=1):\n",
    "                                    mid_time = start_time + duration / 2\n",
    "                                    y_pos = y_max - (y_max - y_min) * 0.05\n",
    "                                    ax.text(mid_time, y_pos, label_name, \n",
    "                                           ha='center', va='top', rotation=0,\n",
    "                                           fontsize=9, alpha=0.9,\n",
    "                                           bbox=dict(boxstyle='round,pad=0.2', \n",
    "                                                   facecolor='white', alpha=0.8))\n",
    "                    \n",
    "                    print(f\"üè∑Ô∏è Showing {len(label_segments)} label segments\")\n",
    "            \n",
    "            # Format all axes\n",
    "            for ax in axes:\n",
    "                ax.set_xlim(plot_start, plot_end)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "                ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=max(1, window_mins//10)))\n",
    "                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "            \n",
    "            # Add legends\n",
    "            legend_elements = []\n",
    "            \n",
    "            # Add sensor channel legend for overlay mode\n",
    "            if plot_style.value == 'overlay' and len(selected_channels) <= 15:\n",
    "                sensor_legend = axes[0].legend(bbox_to_anchor=(1.02, 1), loc='upper left', \n",
    "                                             fontsize=8, title='Sensor Channels')\n",
    "                axes[0].add_artist(sensor_legend)  # Keep this legend when adding activity legend\n",
    "            \n",
    "            # Add activity labels legend if showing labels\n",
    "            if show_labels.value and len(non_empty_labels) > 0 and visible_activity_labels:\n",
    "                # Create legend handles for visible activity labels\n",
    "                activity_handles = []\n",
    "                for label_name in sorted(visible_activity_labels):\n",
    "                    color = label_colors.get(label_name, 'gray')\n",
    "                    activity_handles.append(Patch(facecolor=color, alpha=label_alpha.value, \n",
    "                                                label=label_name))\n",
    "                \n",
    "                # Position activity legend\n",
    "                if plot_style.value == 'overlay':\n",
    "                    # Place below sensor legend if both exist\n",
    "                    y_pos = 0.7 if len(selected_channels) <= 15 else 1.0\n",
    "                    activity_legend = axes[0].legend(handles=activity_handles, \n",
    "                                                    bbox_to_anchor=(1.02, y_pos), \n",
    "                                                    loc='upper left', fontsize=8, \n",
    "                                                    title='Activities')\n",
    "                else:\n",
    "                    # Place on first subplot for subplots mode\n",
    "                    activity_legend = axes[0].legend(handles=activity_handles, \n",
    "                                                    bbox_to_anchor=(1.02, 1), \n",
    "                                                    loc='upper left', fontsize=8, \n",
    "                                                    title='Activities')\n",
    "                \n",
    "                print(f\"üé® Added legend for {len(visible_activity_labels)} visible activities\")\n",
    "            \n",
    "            # Title and layout\n",
    "            title = f'Combined Data Visualization - {plot_style.value.title()} Mode\\n'\n",
    "            title += f'Window: {plot_start.strftime(\"%H:%M:%S\")} to {plot_end.strftime(\"%H:%M:%S\")} '\n",
    "            title += f'({len(selected_channels)} channels, {len(plot_data)} samples)'\n",
    "            \n",
    "            plt.suptitle(title, fontsize=14, y=0.98)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Adjust layout to accommodate legends\n",
    "            has_sensor_legend = plot_style.value == 'overlay' and len(selected_channels) <= 15\n",
    "            has_activity_legend = show_labels.value and len(non_empty_labels) > 0 and visible_activity_labels\n",
    "            \n",
    "            if plot_style.value == 'overlay':\n",
    "                if has_sensor_legend and has_activity_legend:\n",
    "                    plt.subplots_adjust(right=0.75, top=0.92)  # Space for both legends\n",
    "                elif has_sensor_legend or has_activity_legend:\n",
    "                    plt.subplots_adjust(right=0.85, top=0.92)  # Space for one legend\n",
    "                else:\n",
    "                    plt.subplots_adjust(top=0.92)  # No legends\n",
    "            else:\n",
    "                if has_activity_legend:\n",
    "                    plt.subplots_adjust(right=0.85, top=0.95)  # Space for activity legend\n",
    "                else:\n",
    "                    plt.subplots_adjust(top=0.95)  # No legends\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating plot: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Navigation functions\n",
    "def navigate_backward_5min(btn):\n",
    "    current_time = get_center_time()\n",
    "    new_time = current_time - pd.Timedelta(minutes=5)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def navigate_forward_5min(btn):\n",
    "    current_time = get_center_time()\n",
    "    new_time = current_time + pd.Timedelta(minutes=5)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def navigate_backward_30min(btn):\n",
    "    current_time = get_center_time()\n",
    "    new_time = current_time - pd.Timedelta(minutes=30)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def navigate_forward_30min(btn):\n",
    "    current_time = get_center_time()\n",
    "    new_time = current_time + pd.Timedelta(minutes=30)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def jump_to_data_start(btn):\n",
    "    new_time = data_start + pd.Timedelta(minutes=window_minutes.value/2)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def jump_to_data_center(btn):\n",
    "    update_center_time(data_center)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def jump_to_data_end(btn):\n",
    "    new_time = data_end - pd.Timedelta(minutes=window_minutes.value/2)\n",
    "    update_center_time(new_time)\n",
    "    if auto_plot.value:\n",
    "        plot_data(None)\n",
    "\n",
    "def jump_to_sync_start(btn):\n",
    "    \"\"\"Jump to sync start time\"\"\"\n",
    "    if sync_start_time is not None:\n",
    "        print(f\"üéØ Jumping to sync start: {sync_start_time}\")\n",
    "        \n",
    "        # Check if sync time is within data bounds\n",
    "        if not (data_start <= sync_start_time <= data_end):\n",
    "            print(f\"‚ö†Ô∏è Warning: Sync start time is outside data range!\")\n",
    "            print(f\"   Data range: {data_start} to {data_end}\")\n",
    "            print(f\"   Sync time: {sync_start_time}\")\n",
    "            \n",
    "            # Find closest available time\n",
    "            if sync_start_time < data_start:\n",
    "                print(f\"   Using data start instead: {data_start}\")\n",
    "                update_center_time(data_start)\n",
    "            else:\n",
    "                print(f\"   Using data end instead: {data_end}\")\n",
    "                update_center_time(data_end)\n",
    "        else:\n",
    "            # Check for data availability around sync time\n",
    "            window = pd.Timedelta(minutes=window_minutes.value/2)\n",
    "            mask = (combined_data.index >= sync_start_time - window) & (combined_data.index <= sync_start_time + window)\n",
    "            data_count = combined_data[mask].shape[0]\n",
    "            print(f\"   Data available in ¬±{window_minutes.value/2}min window: {data_count} samples\")\n",
    "            \n",
    "            update_center_time(sync_start_time)\n",
    "        \n",
    "        if auto_plot.value:\n",
    "            plot_data(None)\n",
    "\n",
    "def jump_to_sync_end(btn):\n",
    "    \"\"\"Jump to sync end time\"\"\"\n",
    "    if sync_end_time is not None:\n",
    "        print(f\"üéØ Jumping to sync end: {sync_end_time}\")\n",
    "        \n",
    "        # Check if sync time is within data bounds\n",
    "        if not (data_start <= sync_end_time <= data_end):\n",
    "            print(f\"‚ö†Ô∏è Warning: Sync end time is outside data range!\")\n",
    "            print(f\"   Data range: {data_start} to {data_end}\")\n",
    "            print(f\"   Sync time: {sync_end_time}\")\n",
    "            \n",
    "            # Find closest available time\n",
    "            if sync_end_time < data_start:\n",
    "                print(f\"   Using data start instead: {data_start}\")\n",
    "                update_center_time(data_start)\n",
    "            else:\n",
    "                print(f\"   Using data end instead: {data_end}\")\n",
    "                update_center_time(data_end)\n",
    "        else:\n",
    "            # Check for data availability around sync time\n",
    "            window = pd.Timedelta(minutes=window_minutes.value/2)\n",
    "            mask = (combined_data.index >= sync_end_time - window) & (combined_data.index <= sync_end_time + window)\n",
    "            data_count = combined_data[mask].shape[0]\n",
    "            print(f\"   Data available in ¬±{window_minutes.value/2}min window: {data_count} samples\")\n",
    "            \n",
    "            update_center_time(sync_end_time)\n",
    "        \n",
    "        if auto_plot.value:\n",
    "            plot_data(None)\n",
    "\n",
    "# Connect buttons\n",
    "plot_button.on_click(plot_data)\n",
    "nav_backward_5min.on_click(navigate_backward_5min)\n",
    "nav_forward_5min.on_click(navigate_forward_5min)\n",
    "nav_backward_30min.on_click(navigate_backward_30min)\n",
    "nav_forward_30min.on_click(navigate_forward_30min)\n",
    "jump_data_start.on_click(jump_to_data_start)\n",
    "jump_data_center.on_click(jump_to_data_center)\n",
    "jump_data_end.on_click(jump_to_data_end)\n",
    "\n",
    "# Connect sync jump buttons if they exist\n",
    "if sync_start_time is not None:\n",
    "    jump_sync_start.on_click(jump_to_sync_start)\n",
    "if sync_end_time is not None:\n",
    "    jump_sync_end.on_click(jump_to_sync_end)\n",
    "\n",
    "# Initialize channel selection\n",
    "update_channel_selection()\n",
    "\n",
    "print(\"‚úÖ Interactive controls ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0368e4",
   "metadata": {},
   "source": [
    "## 5. Interactive Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594e6cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è Interactive Control Panel\n",
      "Use the controls below to explore your combined sensor data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0758c08488340108147875e17e0ebce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üéõÔ∏è Combined Data Interactive Visualizer</h3>'), HBox(children=(VBox(children=(H‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Interactive visualizer ready!\n",
      "\n",
      "üìù Instructions:\n",
      "  1. Select sensor groups to focus on specific sensor types\n",
      "  2. Choose individual channels to plot\n",
      "  3. Set time window and center time\n",
      "  4. Use navigation buttons to move through data\n",
      "  5. Toggle labels and adjust transparency\n",
      "  6. Choose between overlay or subplot visualization\n",
      "  7. Use sync jump buttons to quickly navigate to sync events\n",
      "\n",
      "üí° Tips:\n",
      "  ‚Ä¢ Use auto-plot for seamless navigation\n",
      "  ‚Ä¢ Overlay mode normalizes data for comparison\n",
      "  ‚Ä¢ Subplot mode shows actual data values\n",
      "  ‚Ä¢ Labels appear as shaded background areas\n",
      "  ‚Ä¢ Sync buttons jump directly to synchronization events\n",
      "  ‚Ä¢ Click 'Plot Data' to refresh manually\n"
     ]
    }
   ],
   "source": [
    "# Create the interactive control panel layout\n",
    "print(\"üéõÔ∏è Interactive Control Panel\")\n",
    "print(\"Use the controls below to explore your combined sensor data\")\n",
    "\n",
    "# Layout controls in organized sections\n",
    "sensor_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>üìä Sensor Selection</h4>\"),\n",
    "    sensor_group_selection,\n",
    "    channel_selection,\n",
    "    plot_style\n",
    "])\n",
    "\n",
    "label_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>üè∑Ô∏è Label Controls</h4>\"),\n",
    "    show_labels,\n",
    "    label_alpha,\n",
    "    label_filter\n",
    "]) if len(non_empty_labels) > 0 else widgets.HTML(\"<p>No labels available</p>\")\n",
    "\n",
    "time_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>‚è±Ô∏è Time Navigation</h4>\"),\n",
    "    center_time_text,\n",
    "    window_minutes,\n",
    "    widgets.HTML(\"<b>Fine Navigation:</b>\"),\n",
    "    widgets.HBox([nav_backward_5min, nav_forward_5min]),\n",
    "    widgets.HTML(\"<b>Coarse Navigation:</b>\"),\n",
    "    widgets.HBox([nav_backward_30min, nav_forward_30min]),\n",
    "    widgets.HTML(\"<b>Quick Jumps:</b>\"),\n",
    "    widgets.HBox([jump_data_start, jump_data_center, jump_data_end]),\n",
    "    widgets.HTML(\"<b>Sync Events:</b>\") if sync_jump_buttons else widgets.HTML(\"\"),\n",
    "    widgets.HBox(sync_jump_buttons) if sync_jump_buttons else widgets.HTML(\"\"),\n",
    "    auto_plot\n",
    "])\n",
    "\n",
    "plot_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>üìà Plot Controls</h4>\"),\n",
    "    plot_button,\n",
    "    widgets.HTML(\"<p><b>Plot Styles:</b></p>\"\n",
    "                 \"<p>‚Ä¢ <b>Overlay</b>: All channels on one plot (normalized)</p>\"\n",
    "                 \"<p>‚Ä¢ <b>Subplots</b>: Each channel in separate subplot</p>\")\n",
    "])\n",
    "\n",
    "# Combine all controls\n",
    "all_controls = widgets.HBox([\n",
    "    sensor_controls,\n",
    "    label_controls,\n",
    "    time_controls,\n",
    "    plot_controls\n",
    "])\n",
    "\n",
    "# Display the interface\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üéõÔ∏è Combined Data Interactive Visualizer</h3>\"),\n",
    "    all_controls,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    plot_output\n",
    "]))\n",
    "\n",
    "print(\"\\nüöÄ Interactive visualizer ready!\")\n",
    "print(\"\\nüìù Instructions:\")\n",
    "print(\"  1. Select sensor groups to focus on specific sensor types\")\n",
    "print(\"  2. Choose individual channels to plot\")\n",
    "print(\"  3. Set time window and center time\")\n",
    "print(\"  4. Use navigation buttons to move through data\")\n",
    "print(\"  5. Toggle labels and adjust transparency\")\n",
    "print(\"  6. Choose between overlay or subplot visualization\")\n",
    "if sync_jump_buttons:\n",
    "    print(\"  7. Use sync jump buttons to quickly navigate to sync events\")\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"  ‚Ä¢ Use auto-plot for seamless navigation\")\n",
    "print(\"  ‚Ä¢ Overlay mode normalizes data for comparison\")\n",
    "print(\"  ‚Ä¢ Subplot mode shows actual data values\")\n",
    "print(\"  ‚Ä¢ Labels appear as shaded background areas\")\n",
    "if sync_jump_buttons:\n",
    "    print(\"  ‚Ä¢ Sync buttons jump directly to synchronization events\")\n",
    "print(\"  ‚Ä¢ Click 'Plot Data' to refresh manually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ad1c6",
   "metadata": {},
   "source": [
    "## 6. Data Statistics and Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c5cdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMBINED DATA QUALITY REPORT ===\n",
      "\n",
      "‚è±Ô∏è Temporal Statistics:\n",
      "  üìÖ Start time: 2024-02-06 09:57:02.789999962\n",
      "  üìÖ End time: 2024-02-07 21:02:45.387000084\n",
      "  ‚è±Ô∏è Total duration: 1 days 11:05:42.597000122\n",
      "  üìä Total samples: 3,158,564\n",
      "  üîÑ Actual sampling frequency: 25.00 Hz\n",
      "  üìè Time resolution: 0 days 00:00:00.040000011\n",
      "\n",
      "üìà Sensor Statistics:\n",
      "  üîß Total sensor groups: 11\n",
      "  üìä Total sensor channels: 29\n",
      "    üìä corsano_wrist_wrist_acc:\n",
      "      Channels: 3\n",
      "      Coverage: 82.6%\n",
      "      Missing values: 1,645,377\n",
      "      Value range: [-3767.000, 3966.000]\n",
      "      Mean ¬± Std: -27.069 ¬± 259.656\n",
      "    üìä cosinuss_ear_ear_acc:\n",
      "      Channels: 3\n",
      "      Coverage: 44.0%\n",
      "      Missing values: 5,311,119\n",
      "      Value range: [-3.430, 2.664]\n",
      "      Mean ¬± Std: -0.156 ¬± 0.439\n",
      "    üìä mbient_acc_x_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-3.063, 3.449]\n",
      "      Mean ¬± Std: -0.031 ¬± 0.487\n",
      "    üìä mbient_acc_y_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-3.439, 10.654]\n",
      "      Mean ¬± Std: 0.031 ¬± 0.833\n",
      "    üìä mbient_acc_z_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-2.581, 3.420]\n",
      "      Mean ¬± Std: -0.409 ¬± 0.580\n",
      "    üìä mbient_gyro_x_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-1093.354, 773.567]\n",
      "      Mean ¬± Std: -1.032 ¬± 7.644\n",
      "    üìä mbient_gyro_y_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-713.323, 919.268]\n",
      "      Mean ¬± Std: -4.046 ¬± 20.697\n",
      "    üìä mbient_gyro_z_axis:\n",
      "      Channels: 1\n",
      "      Coverage: 100.0%\n",
      "      Missing values: 0\n",
      "      Value range: [-1479.360, 868.476]\n",
      "      Mean ¬± Std: -35.010 ¬± 162.348\n",
      "    üìä vivalnk_acc_vivalnk_acc:\n",
      "      Channels: 3\n",
      "      Coverage: 35.5%\n",
      "      Missing values: 6,108,717\n",
      "      Value range: [-2895.000, 4442.000]\n",
      "      Mean ¬± Std: 626.333 ¬± 429.683\n",
      "    üìä sensomative_bottom_bottom_value:\n",
      "      Channels: 11\n",
      "      Coverage: 77.2%\n",
      "      Missing values: 7,924,389\n",
      "      Value range: [0.000, 255.000]\n",
      "      Mean ¬± Std: 47.784 ¬± 39.878\n",
      "    üìä corsano_bioz_bioz_acc:\n",
      "      Channels: 3\n",
      "      Coverage: 84.2%\n",
      "      Missing values: 1,500,774\n",
      "      Value range: [-3636.000, 3847.000]\n",
      "      Mean ¬± Std: -37.846 ¬± 257.441\n",
      "\n",
      "üè∑Ô∏è Label Statistics:\n",
      "  üìã Unique activities: 31\n",
      "  üìä Labeled samples: 1,120,035 (35.5%)\n",
      "  üìä Unlabeled samples: 2,038,529 (64.5%)\n",
      "\n",
      "üè∑Ô∏è Activity Durations:\n",
      "    üè∑Ô∏è dark: 403.6 min (19.2%)\n",
      "    üè∑Ô∏è conversation: 122.9 min (5.8%)\n",
      "    üè∑Ô∏è cycling: 87.8 min (4.2%)\n",
      "    üè∑Ô∏è reading_newspaper: 30.9 min (1.5%)\n",
      "    üè∑Ô∏è eating: 28.3 min (1.3%)\n",
      "    üè∑Ô∏è self_propulsion: 22.8 min (1.1%)\n",
      "    üè∑Ô∏è eating+conversation: 11.3 min (0.5%)\n",
      "    üè∑Ô∏è sitting_wheelchair: 10.2 min (0.5%)\n",
      "    üè∑Ô∏è toilet_routine: 9.0 min (0.4%)\n",
      "    üè∑Ô∏è assisted_propulsion+using_phone: 2.1 min (0.1%)\n",
      "    üè∑Ô∏è using_phone: 2.1 min (0.1%)\n",
      "    üè∑Ô∏è using_computer: 1.9 min (0.1%)\n",
      "    üè∑Ô∏è reading: 1.9 min (0.1%)\n",
      "    üè∑Ô∏è put_on_clothes: 1.9 min (0.1%)\n",
      "    üè∑Ô∏è manipulating: 1.2 min (0.1%)\n",
      "    ... and 16 more activities\n",
      "\n",
      "üîÑ Label Transitions: 381\n",
      "  üìä Average segment length: 8290 samples (331.6s)\n",
      "\n",
      "üíæ Memory Usage:\n",
      "  üìä DataFrame size: 902.6 MB\n",
      "  üíΩ File size: 738.4 MB\n",
      "  üìà Compression ratio: 1.2x\n",
      "\n",
      "‚úÖ Overall Data Quality:\n",
      "  üìä Sensor data coverage: 75.45%\n",
      "  üè∑Ô∏è Label coverage: 35.46%\n",
      "  ‚è±Ô∏è Temporal consistency: ‚úÖ Regular 25.0Hz sampling\n",
      "  üîÑ Synchronization: ‚úÖ All sensors aligned\n",
      "  ‚ùå Poor data quality. Significant missing data detected.\n",
      "\n",
      "üìÅ Data ready for use! Load with:\n",
      "import pickle\n",
      "with open('/scai_data3/scratch/stirnimann_r/results/OutSense-036/OutSense-036_combined_data.pkl', 'rb') as f:\n",
      "    data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed statistics about the combined data\n",
    "print(\"=== COMBINED DATA QUALITY REPORT ===\")\n",
    "\n",
    "# Time statistics\n",
    "sampling_freq = len(combined_data) / (data_end - data_start).total_seconds()\n",
    "print(f\"\\n‚è±Ô∏è Temporal Statistics:\")\n",
    "print(f\"  üìÖ Start time: {data_start}\")\n",
    "print(f\"  üìÖ End time: {data_end}\")\n",
    "print(f\"  ‚è±Ô∏è Total duration: {data_end - data_start}\")\n",
    "print(f\"  üìä Total samples: {len(combined_data):,}\")\n",
    "print(f\"  üîÑ Actual sampling frequency: {sampling_freq:.2f} Hz\")\n",
    "print(f\"  üìè Time resolution: {(data_end - data_start) / len(combined_data)}\")\n",
    "\n",
    "# Sensor statistics\n",
    "print(f\"\\nüìà Sensor Statistics:\")\n",
    "print(f\"  üîß Total sensor groups: {len(sensor_groups)}\")\n",
    "print(f\"  üìä Total sensor channels: {len(sensor_columns)}\")\n",
    "\n",
    "for sensor_name, channels in sensor_groups.items():\n",
    "    # Calculate statistics for this sensor group\n",
    "    sensor_data = combined_data[channels]\n",
    "    total_values = sensor_data.size\n",
    "    missing_values = sensor_data.isnull().sum().sum()\n",
    "    coverage = (total_values - missing_values) / total_values * 100\n",
    "    \n",
    "    print(f\"    üìä {sensor_name}:\")\n",
    "    print(f\"      Channels: {len(channels)}\")\n",
    "    print(f\"      Coverage: {coverage:.1f}%\")\n",
    "    print(f\"      Missing values: {missing_values:,}\")\n",
    "    \n",
    "    # Value ranges\n",
    "    numeric_data = sensor_data.select_dtypes(include=[np.number])\n",
    "    if not numeric_data.empty:\n",
    "        overall_min = numeric_data.min().min()\n",
    "        overall_max = numeric_data.max().max()\n",
    "        overall_mean = numeric_data.mean().mean()\n",
    "        overall_std = numeric_data.std().mean()\n",
    "        \n",
    "        print(f\"      Value range: [{overall_min:.3f}, {overall_max:.3f}]\")\n",
    "        print(f\"      Mean ¬± Std: {overall_mean:.3f} ¬± {overall_std:.3f}\")\n",
    "\n",
    "# Label statistics\n",
    "if len(non_empty_labels) > 0:\n",
    "    print(f\"\\nüè∑Ô∏è Label Statistics:\")\n",
    "    total_labeled = (combined_data[label_column] != '').sum()\n",
    "    label_coverage = total_labeled / len(combined_data) * 100\n",
    "    \n",
    "    print(f\"  üìã Unique activities: {len(non_empty_labels)}\")\n",
    "    print(f\"  üìä Labeled samples: {total_labeled:,} ({label_coverage:.1f}%)\")\n",
    "    print(f\"  üìä Unlabeled samples: {len(combined_data) - total_labeled:,} ({100-label_coverage:.1f}%)\")\n",
    "    \n",
    "    # Calculate label durations\n",
    "    print(f\"\\nüè∑Ô∏è Activity Durations:\")\n",
    "    for label, count in non_empty_labels.head(15).items():\n",
    "        duration_seconds = count / sampling_freq\n",
    "        duration_minutes = duration_seconds / 60\n",
    "        percentage = count / len(combined_data) * 100\n",
    "        \n",
    "        if duration_minutes >= 1:\n",
    "            print(f\"    üè∑Ô∏è {label}: {duration_minutes:.1f} min ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"    üè∑Ô∏è {label}: {duration_seconds:.1f} sec ({percentage:.1f}%)\")\n",
    "    \n",
    "    if len(non_empty_labels) > 15:\n",
    "        remaining = len(non_empty_labels) - 15\n",
    "        print(f\"    ... and {remaining} more activities\")\n",
    "        \n",
    "    # Label transitions\n",
    "    label_changes = (combined_data[label_column] != combined_data[label_column].shift()).sum()\n",
    "    print(f\"\\nüîÑ Label Transitions: {label_changes:,}\")\n",
    "    avg_segment_length = len(combined_data) / label_changes if label_changes > 0 else 0\n",
    "    avg_segment_duration = avg_segment_length / sampling_freq\n",
    "    print(f\"  üìä Average segment length: {avg_segment_length:.0f} samples ({avg_segment_duration:.1f}s)\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nüè∑Ô∏è Label Statistics: No labels available\")\n",
    "\n",
    "# Memory usage\n",
    "memory_usage = combined_data.memory_usage(deep=True).sum()\n",
    "memory_mb = memory_usage / (1024 * 1024)\n",
    "print(f\"\\nüíæ Memory Usage:\")\n",
    "print(f\"  üìä DataFrame size: {memory_mb:.1f} MB\")\n",
    "print(f\"  üíΩ File size: {file_size_mb:.1f} MB\")\n",
    "print(f\"  üìà Compression ratio: {memory_mb/file_size_mb:.1f}x\")\n",
    "\n",
    "# Data quality summary\n",
    "total_missing = combined_data[sensor_columns].isnull().sum().sum()\n",
    "total_sensor_values = len(combined_data) * len(sensor_columns)\n",
    "overall_coverage = (total_sensor_values - total_missing) / total_sensor_values * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Overall Data Quality:\")\n",
    "print(f\"  üìä Sensor data coverage: {overall_coverage:.2f}%\")\n",
    "print(f\"  üè∑Ô∏è Label coverage: {label_coverage:.2f}%\" if len(non_empty_labels) > 0 else \"  üè∑Ô∏è Label coverage: 0%\")\n",
    "print(f\"  ‚è±Ô∏è Temporal consistency: ‚úÖ Regular {sampling_freq:.1f}Hz sampling\")\n",
    "print(f\"  üîÑ Synchronization: ‚úÖ All sensors aligned\")\n",
    "\n",
    "if overall_coverage > 95:\n",
    "    print(f\"  üåü Excellent data quality! Ready for AI preprocessing.\")\n",
    "elif overall_coverage > 90:\n",
    "    print(f\"  ‚úÖ Good data quality. Minor gaps acceptable for most applications.\")\n",
    "elif overall_coverage > 80:\n",
    "    print(f\"  ‚ö†Ô∏è Moderate data quality. Consider gap filling strategies.\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Poor data quality. Significant missing data detected.\")\n",
    "\n",
    "print(f\"\\nüìÅ Data ready for use! Load with:\")\n",
    "print(f\"import pickle\")\n",
    "print(f\"with open('{combined_data_path}', 'rb') as f:\")\n",
    "print(f\"    data = pickle.load(f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6fc96",
   "metadata": {},
   "source": [
    "## 7. Sync Events Data Availability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610d5bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYNC EVENTS DATA AVAILABILITY CHECK ===\n",
      "üéØ Checking data availability around sync events for OutSense-036\n",
      "üìÖ Sync Start: 2024-02-06 09:51:10\n",
      "üìÖ Sync End: 2024-02-08 10:23:35\n",
      "‚è±Ô∏è Sync Duration: 2 days 00:32:25\n",
      "\n",
      "üìä Combined Data Time Bounds:\n",
      "  üìÖ Data Start: 2024-02-06 09:57:02.789999962\n",
      "  üìÖ Data End: 2024-02-07 21:02:45.387000084\n",
      "  ‚è±Ô∏è Data Duration: 1 days 11:05:42.597000122\n",
      "\n",
      "üîç Sync Event Coverage:\n",
      "  üéØ Sync Start in data range: ‚ùå False\n",
      "  üéØ Sync End in data range: ‚ùå False\n",
      "    ‚ö†Ô∏è Sync start is 0 days 00:05:52.789999962 before data start\n",
      "    ‚ö†Ô∏è Sync end is 0 days 13:20:49.612999916 after data end\n",
      "\n",
      "üìä Data availability around Sync Start (2024-02-06 09:51:10):\n",
      "    ‚ùå ¬±1min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-06 09:57:02.789999962 to 2024-02-06 09:51:40\n",
      "    ‚ùå ¬±5min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-06 09:57:02.789999962 to 2024-02-06 09:53:40\n",
      "    ‚ùå ¬±10min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-06 09:57:02.789999962 to 2024-02-06 09:56:10\n",
      "    ‚úÖ ¬±30min window: 13681 samples, 98.7% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-06 09:57:02.789999962 to 2024-02-06 10:06:10\n",
      "        First data: 2024-02-06 09:57:02.789999962\n",
      "        Last data: 2024-02-06 10:06:09.990333455\n",
      "        Sampling: avg gap 0 days 00:00:00.040000024, max gap 0 days 00:00:00.040000025\n",
      "        Available sensors: 29/29 (['corsano_wrist_wrist_acc_x', 'corsano_wrist_wrist_acc_y', 'corsano_wrist_wrist_acc_z', 'cosinuss_ear_ear_acc_x', 'cosinuss_ear_ear_acc_y']...)\n",
      "\n",
      "üìä Data availability around Sync End (2024-02-08 10:23:35):\n",
      "    ‚ùå ¬±1min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-08 10:23:05 to 2024-02-07 21:02:45.387000084\n",
      "    ‚ùå ¬±5min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-08 10:21:05 to 2024-02-07 21:02:45.387000084\n",
      "    ‚ùå ¬±10min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-08 10:18:35 to 2024-02-07 21:02:45.387000084\n",
      "    ‚ùå ¬±30min window: 0 samples, 0.0% sensor data, 0.0% labeled\n",
      "        Time range: 2024-02-08 10:08:35 to 2024-02-07 21:02:45.387000084\n",
      "\n",
      "üåç Timezone and Format Analysis:\n",
      "  üìÖ Sync Start timezone: None\n",
      "  üìÖ Data Start timezone: None\n",
      "  üìÖ Data timezone info: None\n",
      "\n",
      "üîß Testing Alternative Time Interpretations:\n",
      "    üéØ With +1h offset: Start in range: True, End in range: False\n",
      "      üìä Adjusted Start (2024-02-06 10:51:10): 15000 samples in ¬±5min window\n",
      "    üéØ With +3h offset: Start in range: True, End in range: False\n",
      "      üìä Adjusted Start (2024-02-06 12:51:10): 15000 samples in ¬±5min window\n",
      "    üéØ With +6h offset: Start in range: True, End in range: False\n",
      "      üìä Adjusted Start (2024-02-06 15:51:10): 15000 samples in ¬±5min window\n",
      "    üéØ With +12h offset: Start in range: True, End in range: False\n",
      "      üìä Adjusted Start (2024-02-06 21:51:10): 15000 samples in ¬±5min window\n",
      "\n",
      "üéØ Exact Timestamp Matching:\n",
      "  üìç Exact sync start match: ‚ùå False\n",
      "  üìç Exact sync end match: ‚ùå False\n",
      "  üéØ Closest to sync start: 2024-02-06 09:57:02.789999962 (diff: 0 days 00:05:52.789999962)\n",
      "  üéØ Closest to sync end: 2024-02-07 21:02:45.387000084 (diff: 0 days 13:20:49.612999916)\n",
      "    üìä Data at closest start timestamp: Available\n",
      "    üìä Sample values: [np.float64(-286.0) np.float64(-150.0) np.float64(413.0)\n",
      " np.float64(0.51475) np.float64(-0.9450000000000001)]\n",
      "\n",
      "üí° Recommendations:\n",
      "  üîß Sync events are outside data time range:\n",
      "     - Check if sync events file has correct timestamps\n",
      "     - Verify timezone consistency between sync events and sensor data\n",
      "     - Consider if data preprocessing removed sync event periods\n",
      "     - Check if subject ID matches between sync events and data files\n",
      "  üìä To investigate further:\n",
      "     - Use the sync jump buttons in the interactive visualizer\n",
      "     - Check the original data files before preprocessing\n",
      "     - Verify the Data_Preprocessing script alignment logic\n"
     ]
    }
   ],
   "source": [
    "# Debug sync events data availability\n",
    "print(\"=== SYNC EVENTS DATA AVAILABILITY CHECK ===\")\n",
    "\n",
    "if sync_start_time is not None and sync_end_time is not None:\n",
    "    print(f\"üéØ Checking data availability around sync events for {SUBJECT_ID}\")\n",
    "    print(f\"üìÖ Sync Start: {sync_start_time}\")\n",
    "    print(f\"üìÖ Sync End: {sync_end_time}\")\n",
    "    print(f\"‚è±Ô∏è Sync Duration: {sync_end_time - sync_start_time}\")\n",
    "    \n",
    "    # Check data time bounds\n",
    "    print(f\"\\nüìä Combined Data Time Bounds:\")\n",
    "    print(f\"  üìÖ Data Start: {data_start}\")\n",
    "    print(f\"  üìÖ Data End: {data_end}\")\n",
    "    print(f\"  ‚è±Ô∏è Data Duration: {data_end - data_start}\")\n",
    "    \n",
    "    # Check if sync times fall within data bounds\n",
    "    sync_start_in_data = data_start <= sync_start_time <= data_end\n",
    "    sync_end_in_data = data_start <= sync_end_time <= data_end\n",
    "    \n",
    "    print(f\"\\nüîç Sync Event Coverage:\")\n",
    "    print(f\"  üéØ Sync Start in data range: {'‚úÖ' if sync_start_in_data else '‚ùå'} {sync_start_in_data}\")\n",
    "    print(f\"  üéØ Sync End in data range: {'‚úÖ' if sync_end_in_data else '‚ùå'} {sync_end_in_data}\")\n",
    "    \n",
    "    if not sync_start_in_data:\n",
    "        if sync_start_time < data_start:\n",
    "            time_diff = data_start - sync_start_time\n",
    "            print(f\"    ‚ö†Ô∏è Sync start is {time_diff} before data start\")\n",
    "        else:\n",
    "            time_diff = sync_start_time - data_end\n",
    "            print(f\"    ‚ö†Ô∏è Sync start is {time_diff} after data end\")\n",
    "    \n",
    "    if not sync_end_in_data:\n",
    "        if sync_end_time < data_start:\n",
    "            time_diff = data_start - sync_end_time\n",
    "            print(f\"    ‚ö†Ô∏è Sync end is {time_diff} before data start\")\n",
    "        else:\n",
    "            time_diff = sync_end_time - data_end\n",
    "            print(f\"    ‚ö†Ô∏è Sync end is {time_diff} after data end\")\n",
    "    \n",
    "    # Check data availability around sync events with different window sizes\n",
    "    window_sizes = [1, 5, 10, 30]  # minutes\n",
    "    \n",
    "    for event_name, event_time in [(\"Sync Start\", sync_start_time), (\"Sync End\", sync_end_time)]:\n",
    "        print(f\"\\nüìä Data availability around {event_name} ({event_time}):\")\n",
    "        \n",
    "        for window_min in window_sizes:\n",
    "            half_window = pd.Timedelta(minutes=window_min/2)\n",
    "            window_start = event_time - half_window\n",
    "            window_end = event_time + half_window\n",
    "            \n",
    "            # Count data points in window\n",
    "            mask = (combined_data.index >= window_start) & (combined_data.index <= window_end)\n",
    "            data_in_window = combined_data[mask]\n",
    "            \n",
    "            # Check sensor data availability\n",
    "            sensor_data_in_window = data_in_window[sensor_columns]\n",
    "            non_null_count = sensor_data_in_window.notna().sum().sum()\n",
    "            total_possible = len(data_in_window) * len(sensor_columns)\n",
    "            coverage = (non_null_count / total_possible * 100) if total_possible > 0 else 0\n",
    "            \n",
    "            # Check label data availability\n",
    "            label_data_in_window = data_in_window[label_column] if label_column in data_in_window.columns else pd.Series()\n",
    "            labeled_count = (label_data_in_window != '').sum() if len(label_data_in_window) > 0 else 0\n",
    "            label_coverage = (labeled_count / len(data_in_window) * 100) if len(data_in_window) > 0 else 0\n",
    "            \n",
    "            status = \"‚úÖ\" if len(data_in_window) > 0 else \"‚ùå\"\n",
    "            print(f\"    {status} ¬±{window_min}min window: {len(data_in_window)} samples, {coverage:.1f}% sensor data, {label_coverage:.1f}% labeled\")\n",
    "            \n",
    "            # Show exact time bounds that would be plotted\n",
    "            actual_start = max(window_start, data_start)\n",
    "            actual_end = min(window_end, data_end)\n",
    "            print(f\"        Time range: {actual_start} to {actual_end}\")\n",
    "            \n",
    "            if len(data_in_window) > 0:\n",
    "                # Show first and last timestamps with data\n",
    "                print(f\"        First data: {data_in_window.index.min()}\")\n",
    "                print(f\"        Last data: {data_in_window.index.max()}\")\n",
    "                \n",
    "                # Check for gaps in data around event\n",
    "                time_diffs = data_in_window.index.to_series().diff()\n",
    "                max_gap = time_diffs.max()\n",
    "                avg_gap = time_diffs.mean()\n",
    "                print(f\"        Sampling: avg gap {avg_gap}, max gap {max_gap}\")\n",
    "                \n",
    "                # Show sample of available sensor channels\n",
    "                available_sensors = sensor_data_in_window.dropna(axis=1, how='all').columns\n",
    "                print(f\"        Available sensors: {len(available_sensors)}/{len(sensor_columns)} ({list(available_sensors[:5])}{'...' if len(available_sensors) > 5 else ''})\")\n",
    "    \n",
    "    # Additional checks for timezone issues\n",
    "    print(f\"\\nüåç Timezone and Format Analysis:\")\n",
    "    print(f\"  üìÖ Sync Start timezone: {sync_start_time.tz}\")\n",
    "    print(f\"  üìÖ Data Start timezone: {data_start.tz}\")\n",
    "    print(f\"  üìÖ Data timezone info: {combined_data.index.tz}\")\n",
    "    \n",
    "    # Try different time formats or offsets\n",
    "    print(f\"\\nüîß Testing Alternative Time Interpretations:\")\n",
    "    \n",
    "    # Test if there's a timezone offset issue\n",
    "    for offset_hours in [-12, -6, -3, -1, 0, 1, 3, 6, 12]:\n",
    "        adjusted_sync_start = sync_start_time + pd.Timedelta(hours=offset_hours)\n",
    "        adjusted_sync_end = sync_end_time + pd.Timedelta(hours=offset_hours)\n",
    "        \n",
    "        start_in_range = data_start <= adjusted_sync_start <= data_end\n",
    "        end_in_range = data_start <= adjusted_sync_end <= data_end\n",
    "        \n",
    "        if start_in_range or end_in_range:\n",
    "            print(f\"    üéØ With {offset_hours:+}h offset: Start in range: {start_in_range}, End in range: {end_in_range}\")\n",
    "            \n",
    "            # Check data around adjusted times\n",
    "            for event_name, adjusted_time in [(\"Adjusted Start\", adjusted_sync_start), (\"Adjusted End\", adjusted_sync_end)]:\n",
    "                if data_start <= adjusted_time <= data_end:\n",
    "                    window = pd.Timedelta(minutes=5)\n",
    "                    mask = (combined_data.index >= adjusted_time - window) & (combined_data.index <= adjusted_time + window)\n",
    "                    data_count = combined_data[mask].shape[0]\n",
    "                    print(f\"      üìä {event_name} ({adjusted_time}): {data_count} samples in ¬±5min window\")\n",
    "    \n",
    "    # Check for exact timestamp matches\n",
    "    print(f\"\\nüéØ Exact Timestamp Matching:\")\n",
    "    exact_sync_start_match = sync_start_time in combined_data.index\n",
    "    exact_sync_end_match = sync_end_time in combined_data.index\n",
    "    \n",
    "    print(f\"  üìç Exact sync start match: {'‚úÖ' if exact_sync_start_match else '‚ùå'} {exact_sync_start_match}\")\n",
    "    print(f\"  üìç Exact sync end match: {'‚úÖ' if exact_sync_end_match else '‚ùå'} {exact_sync_end_match}\")\n",
    "    \n",
    "    # Find nearest timestamps\n",
    "    if len(combined_data) > 0:\n",
    "        # Find closest timestamps to sync events\n",
    "        time_diffs_start = abs(combined_data.index - sync_start_time)\n",
    "        time_diffs_end = abs(combined_data.index - sync_end_time)\n",
    "        \n",
    "        closest_start_idx = time_diffs_start.argmin()\n",
    "        closest_end_idx = time_diffs_end.argmin()\n",
    "        \n",
    "        closest_start_time = combined_data.index[closest_start_idx]\n",
    "        closest_end_time = combined_data.index[closest_end_idx]\n",
    "        \n",
    "        start_diff = abs(closest_start_time - sync_start_time)\n",
    "        end_diff = abs(closest_end_time - sync_end_time)\n",
    "        \n",
    "        print(f\"  üéØ Closest to sync start: {closest_start_time} (diff: {start_diff})\")\n",
    "        print(f\"  üéØ Closest to sync end: {closest_end_time} (diff: {end_diff})\")\n",
    "        \n",
    "        # Show data around closest timestamps\n",
    "        if start_diff <= pd.Timedelta(hours=1):\n",
    "            print(f\"    üìä Data at closest start timestamp: Available\")\n",
    "            sample_data = combined_data.loc[closest_start_time, sensor_columns[:5]]\n",
    "            print(f\"    üìä Sample values: {sample_data.values}\")\n",
    "        \n",
    "        if end_diff <= pd.Timedelta(hours=1):\n",
    "            print(f\"    üìä Data at closest end timestamp: Available\")\n",
    "            sample_data = combined_data.loc[closest_end_time, sensor_columns[:5]]\n",
    "            print(f\"    üìä Sample values: {sample_data.values}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No sync events available for analysis\")\n",
    "    print(\"This could mean:\")\n",
    "    print(\"  1. Sync events file doesn't exist\")\n",
    "    print(\"  2. No sync events found for this subject\")\n",
    "    print(\"  3. Sync events are not properly formatted\")\n",
    "\n",
    "# Recommend actions based on findings\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "if sync_start_time is not None and sync_end_time is not None:\n",
    "    if not (data_start <= sync_start_time <= data_end and data_start <= sync_end_time <= data_end):\n",
    "        print(\"  üîß Sync events are outside data time range:\")\n",
    "        print(\"     - Check if sync events file has correct timestamps\")\n",
    "        print(\"     - Verify timezone consistency between sync events and sensor data\")\n",
    "        print(\"     - Consider if data preprocessing removed sync event periods\")\n",
    "        print(\"     - Check if subject ID matches between sync events and data files\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ Sync events are within data time range\")\n",
    "        print(\"     - Data should be available for plotting around sync events\")\n",
    "        print(\"     - Use the interactive visualizer to navigate to sync times\")\n",
    "\n",
    "print(\"  üìä To investigate further:\")\n",
    "print(\"     - Use the sync jump buttons in the interactive visualizer\")\n",
    "print(\"     - Check the original data files before preprocessing\")\n",
    "print(\"     - Verify the Data_Preprocessing script alignment logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c66dc",
   "metadata": {},
   "source": [
    "## 8. Quick Sync Event Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6e9e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUICK SYNC EVENT DATA TEST ===\n",
      "\n",
      "üéØ Testing Sync Start: 2024-02-06 09:51:10\n",
      "   In data range: ‚ùå False\n",
      "   Event is 0 days 00:05:52.789999962 before data starts\n",
      "\n",
      "üéØ Testing Sync End: 2024-02-08 10:23:35\n",
      "   In data range: ‚ùå False\n",
      "   Event is 0 days 13:20:49.612999916 after data ends\n",
      "\n",
      "‚ùå SYNC EVENT DATA TEST FAILED\n",
      "   Data is NOT available around sync events\n",
      "   Check the detailed analysis above for troubleshooting\n",
      "\n",
      "üîç ADDITIONAL DEBUGGING INFO:\n",
      "\n",
      "Data timestamps near sync start time:\n",
      "   Found 171181 samples within ¬±2 hours of sync start\n",
      "   First 5 timestamps: [Timestamp('2024-02-06 09:57:02.789999962'), Timestamp('2024-02-06 09:57:02.829999986'), Timestamp('2024-02-06 09:57:02.870000010'), Timestamp('2024-02-06 09:57:02.910000035'), Timestamp('2024-02-06 09:57:02.950000059')]\n",
      "   Last 5 timestamps: [Timestamp('2024-02-06 11:51:09.834172927'), Timestamp('2024-02-06 11:51:09.874172951'), Timestamp('2024-02-06 11:51:09.914172975'), Timestamp('2024-02-06 11:51:09.954173'), Timestamp('2024-02-06 11:51:09.994173024')]\n"
     ]
    }
   ],
   "source": [
    "# Quick test function to check sync event data\n",
    "def quick_sync_check():\n",
    "    \"\"\"Quick function to test data availability around sync events\"\"\"\n",
    "    print(\"=== QUICK SYNC EVENT DATA TEST ===\")\n",
    "    \n",
    "    if sync_start_time is None or sync_end_time is None:\n",
    "        print(\"‚ùå No sync events available for testing\")\n",
    "        return False\n",
    "    \n",
    "    success = True\n",
    "    \n",
    "    for event_name, event_time in [(\"Sync Start\", sync_start_time), (\"Sync End\", sync_end_time)]:\n",
    "        print(f\"\\nüéØ Testing {event_name}: {event_time}\")\n",
    "        \n",
    "        # Check if event is in data range\n",
    "        in_range = data_start <= event_time <= data_end\n",
    "        print(f\"   In data range: {'‚úÖ' if in_range else '‚ùå'} {in_range}\")\n",
    "        \n",
    "        if not in_range:\n",
    "            success = False\n",
    "            if event_time < data_start:\n",
    "                print(f\"   Event is {data_start - event_time} before data starts\")\n",
    "            else:\n",
    "                print(f\"   Event is {event_time - data_end} after data ends\")\n",
    "            continue\n",
    "        \n",
    "        # Test different window sizes\n",
    "        for window_min in [1, 5, 10]:\n",
    "            half_window = pd.Timedelta(minutes=window_min/2)\n",
    "            window_start = max(event_time - half_window, data_start)\n",
    "            window_end = min(event_time + half_window, data_end)\n",
    "            \n",
    "            mask = (combined_data.index >= window_start) & (combined_data.index <= window_end)\n",
    "            data_in_window = combined_data[mask]\n",
    "            \n",
    "            if len(data_in_window) > 0:\n",
    "                print(f\"   ‚úÖ ¬±{window_min}min window: {len(data_in_window)} samples available\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå ¬±{window_min}min window: No data available\")\n",
    "                success = False\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\n‚úÖ SYNC EVENT DATA TEST PASSED\")\n",
    "        print(\"   Data is available around sync events\")\n",
    "        print(\"   You should be able to plot sync event data in the interactive visualizer\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå SYNC EVENT DATA TEST FAILED\")\n",
    "        print(\"   Data is NOT available around sync events\")\n",
    "        print(\"   Check the detailed analysis above for troubleshooting\")\n",
    "    \n",
    "    return success\n",
    "\n",
    "# Run the quick test\n",
    "test_result = quick_sync_check()\n",
    "\n",
    "# If test fails, provide additional debugging\n",
    "if not test_result and sync_start_time is not None:\n",
    "    print(f\"\\nüîç ADDITIONAL DEBUGGING INFO:\")\n",
    "    \n",
    "    # Show sample of data timestamps around sync events\n",
    "    print(f\"\\nData timestamps near sync start time:\")\n",
    "    sync_area_mask = (combined_data.index >= sync_start_time - pd.Timedelta(hours=2)) & (combined_data.index <= sync_start_time + pd.Timedelta(hours=2))\n",
    "    sync_area_data = combined_data[sync_area_mask]\n",
    "    \n",
    "    if len(sync_area_data) > 0:\n",
    "        print(f\"   Found {len(sync_area_data)} samples within ¬±2 hours of sync start\")\n",
    "        print(f\"   First 5 timestamps: {sync_area_data.index[:5].tolist()}\")\n",
    "        print(f\"   Last 5 timestamps: {sync_area_data.index[-5:].tolist()}\")\n",
    "    else:\n",
    "        print(f\"   No data found within ¬±2 hours of sync start\")\n",
    "        \n",
    "        # Show actual data time range vs sync time\n",
    "        print(f\"\\nTime comparison:\")\n",
    "        print(f\"   Sync start: {sync_start_time}\")\n",
    "        print(f\"   Data start: {data_start}\")\n",
    "        print(f\"   Data end: {data_end}\")\n",
    "        print(f\"   Difference to data start: {data_start - sync_start_time}\")\n",
    "        print(f\"   Difference to data end: {sync_start_time - data_end}\")\n",
    "\n",
    "# Test plotting around sync events if data is available\n",
    "if test_result and sync_start_time is not None:\n",
    "    print(f\"\\nüìä TESTING PLOT AROUND SYNC START\")\n",
    "    \n",
    "    # Set up for plotting around sync start\n",
    "    center_time_text.value = sync_start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    window_minutes.value = 10  # 10 minute window\n",
    "    \n",
    "    # Select some default channels for testing\n",
    "    if len(sensor_columns) > 0:\n",
    "        test_channels = sensor_columns[:min(3, len(sensor_columns))]\n",
    "        channel_selection.value = test_channels\n",
    "        print(f\"   Selected channels for test: {test_channels}\")\n",
    "        \n",
    "        # Test plot data availability\n",
    "        half_window = pd.Timedelta(minutes=5)\n",
    "        plot_start = sync_start_time - half_window\n",
    "        plot_end = sync_start_time + half_window\n",
    "        \n",
    "        mask = (combined_data.index >= plot_start) & (combined_data.index <= plot_end)\n",
    "        test_plot_data = combined_data[mask]\n",
    "        \n",
    "        print(f\"   Test plot window: {plot_start} to {plot_end}\")\n",
    "        print(f\"   Samples in plot window: {len(test_plot_data)}\")\n",
    "        \n",
    "        if len(test_plot_data) > 0:\n",
    "            print(f\"   ‚úÖ Plot data available - ready for interactive visualization!\")\n",
    "            print(f\"   üí° Click 'Sync Start' button in the interactive visualizer to view\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå No plot data available in test window\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è No sensor columns available for testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
